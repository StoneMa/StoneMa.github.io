<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>Youngs&#39;s Blog</title>
  
  <subtitle>Good Good Study, Day Day Up !</subtitle>
  <link href="/atom.xml" rel="self"/>
  
  <link href="https://stonema.github.io/"/>
  <updated>2020-01-18T02:55:16.982Z</updated>
  <id>https://stonema.github.io/</id>
  
  <author>
    <name>Youngs</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>Welcome Back</title>
    <link href="https://stonema.github.io/2020/01/18/Welcome-Back/"/>
    <id>https://stonema.github.io/2020/01/18/Welcome-Back/</id>
    <published>2020-01-18T02:15:41.000Z</published>
    <updated>2020-01-18T02:55:16.982Z</updated>
    
    <content type="html"><![CDATA[<p>2020, Welcome Back.</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;2020, Welcome Back.&lt;/p&gt;

      
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>Java多线程与线程安全问题</title>
    <link href="https://stonema.github.io/2018/10/12/Java%E5%A4%9A%E7%BA%BF%E7%A8%8B%E4%B8%8E%E7%BA%BF%E7%A8%8B%E5%AE%89%E5%85%A8%E9%97%AE%E9%A2%98/"/>
    <id>https://stonema.github.io/2018/10/12/Java多线程与线程安全问题/</id>
    <published>2018-10-12T06:54:59.000Z</published>
    <updated>2020-01-18T01:45:05.164Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Java中的线程问题"><a href="#Java中的线程问题" class="headerlink" title="Java中的线程问题"></a>Java中的线程问题</h1><h2 id="Servlet是线程安全的吗？"><a href="#Servlet是线程安全的吗？" class="headerlink" title="Servlet是线程安全的吗？"></a>Servlet是线程安全的吗？</h2><p>Servlet 默认是单例模式，在web 容器中只创建一个实例，所以多个线程同时访问servlet的时候，Servlet是线程不安全的。<br>那么 web 容器能为每个请求创建一个Servlet的实例吗？当然是可以的，只要Servlet实现SingleThreadModel接口，就可以了。<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> javax.servlet.SingleThreadModel </span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">MyServlet</span> <span class="keyword">extends</span> <span class="title">HttpServlet</span> <span class="keyword">implements</span> <span class="title">SingleThreadModel</span> </span>&#123;&#125;</span><br></pre></td></tr></table></figure></p><h2 id="变量的线程安全"><a href="#变量的线程安全" class="headerlink" title="变量的线程安全"></a>变量的线程安全</h2><p>只有全局变量和静态变量才会引起线程安全问题，因为它们存在多线程内存共享；<br>局部变量是每个对象独有的，不存在变量共享，也就没有线程安全问题；</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;Java中的线程问题&quot;&gt;&lt;a href=&quot;#Java中的线程问题&quot; class=&quot;headerlink&quot; title=&quot;Java中的线程问题&quot;&gt;&lt;/a&gt;Java中的线程问题&lt;/h1&gt;&lt;h2 id=&quot;Servlet是线程安全的吗？&quot;&gt;&lt;a href=&quot;#Servle
      
    
    </summary>
    
    
      <category term="Java" scheme="https://stonema.github.io/tags/Java/"/>
    
      <category term="线程安全" scheme="https://stonema.github.io/tags/%E7%BA%BF%E7%A8%8B%E5%AE%89%E5%85%A8/"/>
    
  </entry>
  
  <entry>
    <title>求逆序对数量与归并排序</title>
    <link href="https://stonema.github.io/2018/09/30/%E6%B1%82%E9%80%86%E5%BA%8F%E5%AF%B9%E6%95%B0%E9%87%8F%E4%B8%8E%E5%BD%92%E5%B9%B6%E6%8E%92%E5%BA%8F/"/>
    <id>https://stonema.github.io/2018/09/30/求逆序对数量与归并排序/</id>
    <published>2018-09-30T01:02:22.000Z</published>
    <updated>2020-01-18T01:45:05.206Z</updated>
    
    <content type="html"><![CDATA[<h1 id="逆序对统计"><a href="#逆序对统计" class="headerlink" title="逆序对统计"></a>逆序对统计</h1><p>最近写算法题的时候又遇到了这类问题:<br><code>在数组中的两个数字，如果前面一个数字大于后面的数字，则这两个数字组成一个逆序对。输入一个数组,求出这个数组中的逆序对的总数P。</code><br><code>输入：1,2,3,4,5,6,7,0</code><br><code>输出： 7</code><br><code>可以从上面得知，逆序对分别为：&lt;1,0&gt; &lt;2,0&gt; &lt;3,0&gt; &lt;4,0&gt; &lt;5,0&gt; &lt;6,0&gt; &lt;7,0&gt;</code><br>这里问题，一个所有人都能想到的求解方法就是暴力搜索：用两层for循环将数组中的元素全部两两比较一遍，就能得到所有的逆序对数。<br>当然这样的做法也不是不行，但是效果是时间效率非常的低下，时间复杂度是O(n^2);在数据量很大的时候，响应时间会非常的久，这在算法上是不能接受的。<br>今天我们学习另一种思想：Divide And Conquer(分而治之—分治思想)，它的核心思想就是：大事化小，通过解决多个子问题来解决大问题。<br>这个问题的解决思路是和归并排序的思想类似的。<br>话不多说先看代码： （可以用归并排序来作为带入）</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> 数组逆向序对 </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">        数组逆向序对 nx = <span class="keyword">new</span> 数组逆向序对();</span><br><span class="line">        <span class="keyword">int</span>[] a = &#123;<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>, <span class="number">6</span>, <span class="number">7</span>, <span class="number">0</span>&#125;;</span><br><span class="line">        System.out.println(nx.InversePairs(a));</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">InversePairs</span><span class="params">(<span class="keyword">int</span>[] array)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">int</span> n = array.length;</span><br><span class="line">        <span class="keyword">int</span>[] temp = <span class="keyword">new</span> <span class="keyword">int</span>[n];</span><br><span class="line">        <span class="keyword">long</span> ans = MergeSortAndCount(array, <span class="number">0</span>, n - <span class="number">1</span>, temp);</span><br><span class="line">        <span class="keyword">return</span> (<span class="keyword">int</span>) ans;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">long</span> <span class="title">MergeSortAndCount</span><span class="params">(<span class="keyword">int</span>[] array, <span class="keyword">int</span> left, <span class="keyword">int</span> right, <span class="keyword">int</span>[] temp)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">if</span> (left &gt;= right) <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">        <span class="keyword">int</span> mid = (left + right) / <span class="number">2</span>;</span><br><span class="line">        <span class="keyword">long</span> count1 = MergeSortAndCount(array, left, mid, temp);</span><br><span class="line">        <span class="keyword">long</span> count2 = MergeSortAndCount(array, mid + <span class="number">1</span>, right, temp);</span><br><span class="line">        <span class="keyword">long</span> count3 = MergeAndCount(array, left, mid, right, temp);</span><br><span class="line">        <span class="keyword">return</span> (count1 + count2 + count3) % <span class="number">1000000007</span>;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">long</span> <span class="title">MergeAndCount</span><span class="params">(<span class="keyword">int</span>[] array, <span class="keyword">int</span> left, <span class="keyword">int</span> mid, <span class="keyword">int</span> right, <span class="keyword">int</span>[] temp)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">int</span> i = left;</span><br><span class="line">        <span class="keyword">int</span> j = mid + <span class="number">1</span>;</span><br><span class="line">        <span class="keyword">int</span> k = left;</span><br><span class="line">        <span class="keyword">long</span> cnt = <span class="number">0</span>;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">while</span> (i &lt;= mid &amp;&amp; j &lt;= right) &#123;</span><br><span class="line">            <span class="keyword">if</span> (array[i] &lt;= array[j]) &#123;</span><br><span class="line">                temp[k++] = array[i++];</span><br><span class="line">            &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">                temp[k++] = array[j++];</span><br><span class="line">                cnt += mid - i + <span class="number">1</span>;    <span class="comment">// 关键步骤，进行计数</span></span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">while</span> (i &lt;= mid) temp[k++] = array[i++];</span><br><span class="line">        <span class="keyword">while</span> (j &lt;= right) temp[k++] = array[j++];</span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> (i = left; i &lt;= right; ++i) &#123;</span><br><span class="line">            array[i] = temp[i];</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> cnt;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>直接去读这段代码还是有些吃力的，主要有递归程序在，容易把我们绕晕，所以我们以归并排序作为基本思想，来慢慢解决这个问题：</p><h1 id="归并排序"><a href="#归并排序" class="headerlink" title="归并排序"></a>归并排序</h1><p>归并排序，中国人翻译算法的名字的时候通常使用它们的具体含义来命名，这里归并排序也不理外，很容易理解的是，这个排序算法找中肯定包含着：归类与合并，这两个步骤。<br>归类处理，然后合并，这种思想就是分治——分而治之也就是Divide and conquer。</p><h2 id="归并排序的主要思想"><a href="#归并排序的主要思想" class="headerlink" title="归并排序的主要思想"></a>归并排序的主要思想</h2><p>我们上面的找逆序对的问题，其实就是一个简单的归并排序问题，如果你能够充分的理解归并排序，那么上面的找逆序对的问题就不是什么难题。<br>对于排序，我们知道，它最终的目的是将数据进行有序化，是会对数据进行位置交换的算法。（归并排序是一种稳定的排序算法）。它是通过将一个长度为n的数组分成左右两个部分，通常以n/2作为<br>下面我们通过简单的例子来进行讲解，会做到详尽周到，希望能对自己和他人的理解有所帮助。</p><h1 id="实例"><a href="#实例" class="headerlink" title="实例"></a>实例</h1><p>比如我们有一个数组包含4个元素[4,1,2,3]，我们希望通过归并排序，将这个数组进行排序。<br>我们可以通过下面的代码进行实现：<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> 数组逆向序对 </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">        数组逆向序对 nx = <span class="keyword">new</span> 数组逆向序对();</span><br><span class="line">        <span class="keyword">int</span>[] a = [<span class="number">4</span>,<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>&#125;;</span><br><span class="line">        System.out.println(nx.InversePairs(a));</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">InversePairs</span><span class="params">(<span class="keyword">int</span>[] array)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">int</span> n = array.length;</span><br><span class="line">        <span class="keyword">int</span>[] temp = <span class="keyword">new</span> <span class="keyword">int</span>[n];</span><br><span class="line">        <span class="keyword">long</span> ans = MergeSortAndCount(array, <span class="number">0</span>, n - <span class="number">1</span>, temp);</span><br><span class="line">        <span class="keyword">return</span> (<span class="keyword">int</span>) ans;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">long</span> <span class="title">MergeSortAndCount</span><span class="params">(<span class="keyword">int</span>[] array, <span class="keyword">int</span> left, <span class="keyword">int</span> right, <span class="keyword">int</span>[] temp)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">if</span> (left &gt;= right) <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">        <span class="keyword">int</span> mid = (left + right) / <span class="number">2</span>;</span><br><span class="line">        <span class="keyword">long</span> count1 = MergeSortAndCount(array, left, mid, temp);</span><br><span class="line">        <span class="keyword">long</span> count2 = MergeSortAndCount(array, mid + <span class="number">1</span>, right, temp);</span><br><span class="line">        <span class="keyword">long</span> count3 = MergeAndCount(array, left, mid, right, temp);</span><br><span class="line">        <span class="keyword">return</span> (count1 + count2 + count3) % <span class="number">1000000007</span>;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">long</span> <span class="title">MergeAndCount</span><span class="params">(<span class="keyword">int</span>[] array, <span class="keyword">int</span> left, <span class="keyword">int</span> mid, <span class="keyword">int</span> right, <span class="keyword">int</span>[] temp)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">int</span> i = left;</span><br><span class="line">        <span class="keyword">int</span> j = mid + <span class="number">1</span>;</span><br><span class="line">        <span class="keyword">int</span> k = left;</span><br><span class="line">        <span class="keyword">long</span> cnt = <span class="number">0</span>;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">while</span> (i &lt;= mid &amp;&amp; j &lt;= right) &#123;</span><br><span class="line">            <span class="keyword">if</span> (array[i] &lt;= array[j]) &#123;</span><br><span class="line">                temp[k++] = array[i++];</span><br><span class="line">            &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">                temp[k++] = array[j++];</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">while</span> (i &lt;= mid) temp[k++] = array[i++];</span><br><span class="line">        <span class="keyword">while</span> (j &lt;= right) temp[k++] = array[j++];</span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> (i = left; i &lt;= right; ++i) &#123;</span><br><span class="line">            array[i] = temp[i];</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> cnt;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><p>这个代码与我们上面缩写的代码仅仅少一行 <code>cnt += mid - i + 1;</code>。而他们的实现过程是一模一样的，我们一点点对代码进行分析。<br>我们从<code>InversePairs</code>开始：它调用了<code>MergeSortAndCount</code>方法，而<code>MergeSortAndCount</code>方法又调用了<code>MergeAndCount</code>方法。这中间涉及到递归调用，用脑子想的办法去理解可能会有些复杂，我花了一个逻辑调用图，来帮助我们理解归并排序。 归并排序的要点在于，一个是递归，一个是将左右两个部分进行对比排序，如果没有这个递归操作，那么仅仅能保证整个数组以mid为中心，右边比左边大，但是不能保证左右两侧都是有序的，带上递归后，左右两侧分别一直进行递归比较操作，知道这个小的比较区域只剩两个元素，也就完成了子区间的比较。<br><img src="/2018/09/30/求逆序对数量与归并排序/MergeSort.jpg" alt="MergeSort"></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;逆序对统计&quot;&gt;&lt;a href=&quot;#逆序对统计&quot; class=&quot;headerlink&quot; title=&quot;逆序对统计&quot;&gt;&lt;/a&gt;逆序对统计&lt;/h1&gt;&lt;p&gt;最近写算法题的时候又遇到了这类问题:&lt;br&gt;&lt;code&gt;在数组中的两个数字，如果前面一个数字大于后面的数字，则这两个
      
    
    </summary>
    
    
      <category term="算法基础" scheme="https://stonema.github.io/tags/%E7%AE%97%E6%B3%95%E5%9F%BA%E7%A1%80/"/>
    
      <category term="分治" scheme="https://stonema.github.io/tags/%E5%88%86%E6%B2%BB/"/>
    
  </entry>
  
  <entry>
    <title>Java中的this关键字</title>
    <link href="https://stonema.github.io/2018/09/12/Java%E4%B8%AD%E7%9A%84this%E5%85%B3%E9%94%AE%E5%AD%97/"/>
    <id>https://stonema.github.io/2018/09/12/Java中的this关键字/</id>
    <published>2018-09-12T14:37:17.000Z</published>
    <updated>2020-01-18T01:45:05.164Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Java中的this关键字"><a href="#Java中的this关键字" class="headerlink" title="Java中的this关键字"></a>Java中的this关键字</h1><ul><li>this不能用在static方法中！！</li><li>this不能用在static方法中！！</li><li><p>this不能用在static方法中！！<br>重要的事情说三遍！至于原因，我们知道static方法是先于类对象的创建而的，也就是说，在类的加载的过程中，static方法就已经存在了，而this的用法是指向当前加载的对象。这时候static方法所在的类还没有创建出对象，所以this并没有真实对象的引用，所以也就没有this可言。</p><p>(1)this调用本类中的属性，也就是类中的成员变量；<br>(2)this调用本类中的其他方法；<br>(3)this调用本类中的其他构造方法，调用时要放在构造方法的首行。</p></li></ul>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;Java中的this关键字&quot;&gt;&lt;a href=&quot;#Java中的this关键字&quot; class=&quot;headerlink&quot; title=&quot;Java中的this关键字&quot;&gt;&lt;/a&gt;Java中的this关键字&lt;/h1&gt;&lt;ul&gt;
&lt;li&gt;this不能用在static方法中！！&lt;
      
    
    </summary>
    
    
      <category term="Java" scheme="https://stonema.github.io/tags/Java/"/>
    
  </entry>
  
  <entry>
    <title>聚类算法</title>
    <link href="https://stonema.github.io/2018/09/05/%E8%81%9A%E7%B1%BB%E7%AE%97%E6%B3%95/"/>
    <id>https://stonema.github.io/2018/09/05/聚类算法/</id>
    <published>2018-09-05T05:43:53.000Z</published>
    <updated>2020-01-18T01:45:05.210Z</updated>
    
    <content type="html"><![CDATA[<h1 id="常用聚类算法"><a href="#常用聚类算法" class="headerlink" title="常用聚类算法"></a>常用聚类算法</h1><p>聚类：就是把分散的东西，按照相同的类别聚到一起。“物以类聚，人以群分”，它是一种研究，统计的手段，聚类起源于分类，但是不等于分类，聚类与分类的不同在于，<strong>聚类所要求划分的类是未知的</strong>。聚类分析内容非常丰富，有系统聚类法、有序样品聚类法、动态聚类法、模糊聚类法、图论聚类法、聚类预报法等。本文介绍一些基本的聚类算法，具体的代码实现，后续再跟进，首先了解理论思想。</p><p>聚类算法的重点是计算样本项之间的相似度，也叫样本间距的大小。<br>聚类算法和分类算法的区别是：<br>分类算法是有监督学习，基于有标注的历史数据进行算法模型构建。比如神经网络大多构成的是分类器，是通过已知标签的数据来调整网络。<br>聚类算法是无监督学习，数据集中的数据是没有标注的。</p><h2 id="K-Means（K均值）聚类"><a href="#K-Means（K均值）聚类" class="headerlink" title="K-Means（K均值）聚类"></a>K-Means（K均值）聚类</h2><h3 id="算法简介："><a href="#算法简介：" class="headerlink" title="算法简介："></a>算法简介：</h3><p>K-means聚类算法算得上是最著名的聚类方法。Kmeans算法是一个重复移动类中心点的过程，把类的中心点，也称重心(centroids)，移动到其包含成员的平均位置，然后重新划分其内部成员。k是算法计算出的参数，表示类的数量；K-means可以自动分配样本到不同的类，但是不能决定究竟要分几个类。k必须是一个比训练集样本数小的正整数。有时，类的数量是由问题内容指定的。<br>总的来讲K-means算法的数学原型来自于线性代数的最优化问题。</p><h3 id="基本思想："><a href="#基本思想：" class="headerlink" title="基本思想："></a>基本思想：</h3><p>给定一个有M个对象的数据集，构建一个具有k个簇的模型，其中k&lt;=M 满足以下条件：</p><ul><li>每个簇至少包含一个数据对象。</li><li>每个对象属于且仅属于一个簇。</li><li>将满足上述条件的k个簇称为一个合理的聚类划分。</li></ul><p>简单讲就是把给定的总样本数据分成k个类别，首先给定初始划分，然后通过迭代改变样本和簇的隶属关系，使得每次迭代后得到的簇中各个元素到簇中心的距离变小了。</p><h3 id="算法核心思想："><a href="#算法核心思想：" class="headerlink" title="算法核心思想："></a>算法核心思想：</h3><p>每次迭代维护一个最小的样本到簇中心的距离：假设簇划分为（C<em>{1},C</em>{2},C<em>{3}…C</em>{k}），那么我们需要维护的最小平方误差E为：</p><script type="math/tex; mode=display">E=\sum_{k}^{i=1}\sum_{x\in C_{i}}(x-u_{i})^{2}</script><p>二分类：<br><img src="/2018/09/05/聚类算法/PartitionDataIntoTwoClustersExample_02.png" alt="kmeans"><br>多分类：<br><img src="/2018/09/05/聚类算法/kmeans.gif" alt="gif"></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;常用聚类算法&quot;&gt;&lt;a href=&quot;#常用聚类算法&quot; class=&quot;headerlink&quot; title=&quot;常用聚类算法&quot;&gt;&lt;/a&gt;常用聚类算法&lt;/h1&gt;&lt;p&gt;聚类：就是把分散的东西，按照相同的类别聚到一起。“物以类聚，人以群分”，它是一种研究，统计的手段，聚类起源于
      
    
    </summary>
    
      <category term="算法" scheme="https://stonema.github.io/categories/%E7%AE%97%E6%B3%95/"/>
    
    
      <category term="聚类" scheme="https://stonema.github.io/tags/%E8%81%9A%E7%B1%BB/"/>
    
  </entry>
  
  <entry>
    <title>JAVA中的垃圾回收与内存分配-3</title>
    <link href="https://stonema.github.io/2018/09/03/JAVA%E4%B8%AD%E7%9A%84%E5%9E%83%E5%9C%BE%E5%9B%9E%E6%94%B6%E4%B8%8E%E5%86%85%E5%AD%98%E5%88%86%E9%85%8D-3/"/>
    <id>https://stonema.github.io/2018/09/03/JAVA中的垃圾回收与内存分配-3/</id>
    <published>2018-09-03T08:25:41.000Z</published>
    <updated>2020-01-18T01:45:05.162Z</updated>
    
    <content type="html"><![CDATA[<h1 id="垃圾回收"><a href="#垃圾回收" class="headerlink" title="垃圾回收"></a>垃圾回收</h1><p>Java的垃圾回收可以有效防止内存泄露，有效使用空闲内存。内存泄露是指该内存空间使用完毕之后未回收，在不涉及复杂数据结构的一般情况下，Java 的内存泄露表现为一个内存对象的生命周期超出了程序需要它的时间长度，我们有时也将其称为“对象游离”。</p><h2 id="对象晋升"><a href="#对象晋升" class="headerlink" title="对象晋升"></a>对象晋升</h2><ul><li>年龄阈值<br>VM为每个对象定义了一个对象年龄(Age)计数器, 对象在Eden出生如果经第一次Minor GC后仍然存活, 且能被Survivor容纳的话, 将被移动到Survivor空间中, 并将年龄设为1. 以后对象在Survivor区中每熬过一次Minor GC年龄就+1. 当增加到一定程度(-XX:MaxTenuringThreshold, 默认15), 将会晋升到老年代.</li><li>提前晋升: 动态年龄判定<br>然而VM并不总是要求对象的年龄必须达到MaxTenuringThreshold才能晋升老年代: 如果在Survivor空间中相同年龄所有对象大小的总和大于Survivor空间的一半, 年龄大于或等于该年龄的对象就可以直接进入老年代, 而无须等到晋升年龄.</li></ul><h1 id="垃圾回收算法"><a href="#垃圾回收算法" class="headerlink" title="垃圾回收算法"></a>垃圾回收算法</h1><p>分代收集算法 VS 分区收集算法</p><ul><li><p>分代收集<br>当前主流VM垃圾收集都采用”分代收集”(Generational Collection)算法, 这种算法会根据对象存活周期的不同将内存划分为几块, 如JVM中的 新生代、老年代、永久代. 这样就可以根据各年代特点分别采用最适当的GC算法:<br>  在新生代: 每次垃圾收集都能发现大批对象已死, 只有少量存活. 因此选用复制算法, 只需要付出少量存活对象的复制成本就可以完成收集.</p><p>  在老年代: 因为对象存活率高、没有额外空间对它进行分配担保, 就必须采用“标记—清理”或“标记—整理”算法来进行回收, 不必进行内存复制, 且直接腾出空闲内存.</p></li><li>分区收集<br>上面介绍的分代收集算法是将对象的生命周期按长短划分为两个部分, 而分区算法则将整个堆空间划分为连续的不同小区间, 每个小区间独立使用, 独立回收. 这样做的好处是可以控制一次回收多少个小区间.<br>在相同条件下, 堆空间越大, 一次GC耗时就越长, 从而产生的停顿也越长. 为了更好地控制GC产生的停顿时间, 将一块大的内存区域分割为多个小块, 根据目标停顿时间, 每次合理地回收若干个小区间(而不是整个堆), 从而减少一次GC所产生的停顿.</li></ul><h2 id="何时回收-对象生死判定"><a href="#何时回收-对象生死判定" class="headerlink" title=". 何时回收-对象生死判定"></a>. 何时回收-对象生死判定</h2><p>在堆里面存放着Java世界中几乎所有的对象实例, 垃圾收集器在对堆进行回收前, 第一件事就是判断哪些对象已死(可回收).</p><h3 id="可达性分析算法："><a href="#可达性分析算法：" class="headerlink" title="可达性分析算法："></a>可达性分析算法：</h3><p>在主流商用语言(如Java、C#)的主流实现中, 都是通过可达性分析算法来判定对象是否存活的: 通过一系列的称为 GC Roots 的对象作为起点, 然后向下搜索; 搜索所走过的路径称为引用链/Reference Chain, 当一个对象到 GC Roots 没有任何引用链相连时, 即该对象不可达, 也就说明此对象是不可用的, 如下图: Object5、6、7 虽然互有关联, 但它们到GC Roots是不可达的, 因此也会被判定为可回收的对象:<br><img src="/2018/09/03/JAVA中的垃圾回收与内存分配-3/GCROOTS.jpg" alt="gc roots"></p><ul><li>在Java, 可作为GC Roots的对象包括:</li></ul><ol><li>方法区: 类静态属性引用的对象;</li><li>方法区: 常量引用的对象;</li><li>虚拟机栈(本地变量表)中引用的对象.</li><li>本地方法栈JNI(Native方法)中引用的对象。<br>注: 即使在可达性分析算法中不可达的对象, VM也并不是马上对其回收, 因为要真正宣告一个对象死亡, 至少要经历两次标记过程: 第一次是在可达性分析后发现没有与GC Roots相连接的引用链, 第二次是GC对在F-Queue执行队列中的对象进行的小规模标记(对象需要覆盖finalize()方法且没被调用过).</li></ol>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;垃圾回收&quot;&gt;&lt;a href=&quot;#垃圾回收&quot; class=&quot;headerlink&quot; title=&quot;垃圾回收&quot;&gt;&lt;/a&gt;垃圾回收&lt;/h1&gt;&lt;p&gt;Java的垃圾回收可以有效防止内存泄露，有效使用空闲内存。内存泄露是指该内存空间使用完毕之后未回收，在不涉及复杂数据结构的一
      
    
    </summary>
    
      <category term="Java技术" scheme="https://stonema.github.io/categories/Java%E6%8A%80%E6%9C%AF/"/>
    
    
      <category term="Java" scheme="https://stonema.github.io/tags/Java/"/>
    
  </entry>
  
  <entry>
    <title>JAVA中的垃圾回收与内存分配-2</title>
    <link href="https://stonema.github.io/2018/09/01/JAVA%E4%B8%AD%E7%9A%84%E5%9E%83%E5%9C%BE%E5%9B%9E%E6%94%B6%E4%B8%8E%E5%86%85%E5%AD%98%E5%88%86%E9%85%8D-2/"/>
    <id>https://stonema.github.io/2018/09/01/JAVA中的垃圾回收与内存分配-2/</id>
    <published>2018-09-01T07:21:24.000Z</published>
    <updated>2020-01-18T01:45:05.160Z</updated>
    
    <content type="html"><![CDATA[<h1 id="详解内存分配"><a href="#详解内存分配" class="headerlink" title="详解内存分配"></a>详解内存分配</h1><p>通过上一篇文章，我们大题了解了变量和对象都是如何在栈内存和堆内存中分配的，那么我们继续了解。<br>还是老套路先上个图：<br><img src="/2018/09/01/JAVA中的垃圾回收与内存分配-2/JVM.png" alt=""><br>栈，就如同它的名字一样，JVM中的栈内存也是一个后进先出LIFO的数据结构，JVM的垃圾回收器对于并非用new开辟的内存区域，就显得无能为力（来自《JAVA编程思想》第四版中文版P87）。垃圾回收器只知道释放那些由new分配的内存。所以为了应对这种情况，便有了finalize()方法。（详细内容，查资料）<br>要注意一点的是finalize()并不等同于C++中的析构函数。而Java中的垃圾回收符合下面的条件：</p><ol><li>对象可能不被垃圾回收</li><li>垃圾回收并不等于“析构”<h2 id="栈内存与栈操作"><a href="#栈内存与栈操作" class="headerlink" title="栈内存与栈操作"></a>栈内存与栈操作</h2>如上面的图中所示，运行时数据区中有两个栈空间：JVM栈和本地方法栈。<br>栈，常常与线程“联系”在一起，这是因为每当启动一个新线程时，Java虚拟机都会为它分配一个Java栈。<br>Java栈以帧为单位保存线程的运行状态。虚拟机只会直接对Java栈执行两种操作：以帧为单位的压栈和出栈。</li></ol><ul><li>JVM栈<br>JVM栈也就是虚拟机栈，它是线程私有的，也就是说是线程隔离的，即每个线程都有自己独立的虚拟机栈。它的生命周期与线程相同。<br>JVM栈描述的是java方法执行的内存模型，每个方法在执行的同时都会创建一个栈帧，用于存储局部变量表、操作数栈、动态链接、方法出口等信息。<br>每个方法从调用直至执行完成的过程，就对应着一个栈帧在虚拟机栈中入栈到出栈的过程。</li><li>本地方法栈<br>本地方法栈的功能和特点类似于虚拟机栈，均具有线程隔离的特点以及都能抛出StackOverflowError和OutOfMemoryError异常。<br>不同的是，本地方法栈服务的对象是JVM执行的native方法，而虚拟机栈服务的是JVM执行的java方法。详细内容后续更新……</li></ul><h3 id="JVM栈之栈上内存分配"><a href="#JVM栈之栈上内存分配" class="headerlink" title="JVM栈之栈上内存分配"></a>JVM栈之栈上内存分配</h3><p>在JVM中，堆是线程共享的，因此堆上的对象对于各个线程都是共享和可见的，只要持有对象的引用，就可以访问堆中存储的对象数据。虚拟机的垃圾收集系统可以回收堆中不再使用的对象，但对于垃圾收集器来说，无论筛选可回收对象，还是回收和整理内存都需要耗费时间。<br>如果确定一个对象的作用域不会逃逸出方法之外，那可以将这个对象分配在栈上，这样，对象所占用的内存空间就可以随栈帧出栈而销毁。在一般应用中，不会逃逸的局部对象所占的比例很大，如果能使用栈上分配，那大量的对象就会随着方法的结束而自动销毁了，无须通过垃圾收集器回收，可以减小垃圾收集器的负载。JVM允许将线程私有的对象打散分配在栈上，而不是分配在堆上。分配在栈上的好处是可以在函数调用结束后自行销毁，而不需要垃圾回收器的介入，从而提高系统性能。<br><img src="/2018/09/01/JAVA中的垃圾回收与内存分配-2/heaptoStack.jpg" alt="heaptoStack"></p><h2 id="Java堆内存"><a href="#Java堆内存" class="headerlink" title="Java堆内存"></a>Java堆内存</h2><p><img src="/2018/09/01/JAVA中的垃圾回收与内存分配-2/stackMemory.png" alt="堆内存"></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;详解内存分配&quot;&gt;&lt;a href=&quot;#详解内存分配&quot; class=&quot;headerlink&quot; title=&quot;详解内存分配&quot;&gt;&lt;/a&gt;详解内存分配&lt;/h1&gt;&lt;p&gt;通过上一篇文章，我们大题了解了变量和对象都是如何在栈内存和堆内存中分配的，那么我们继续了解。&lt;br&gt;还是老套
      
    
    </summary>
    
      <category term="Java技术" scheme="https://stonema.github.io/categories/Java%E6%8A%80%E6%9C%AF/"/>
    
    
      <category term="Java" scheme="https://stonema.github.io/tags/Java/"/>
    
  </entry>
  
  <entry>
    <title>JAVA中的垃圾回收与内存分配-1</title>
    <link href="https://stonema.github.io/2018/08/31/JAVA%E4%B8%AD%E7%9A%84%E5%9E%83%E5%9C%BE%E5%9B%9E%E6%94%B6%E4%B8%8E%E5%86%85%E5%AD%98%E5%88%86%E9%85%8D-1/"/>
    <id>https://stonema.github.io/2018/08/31/JAVA中的垃圾回收与内存分配-1/</id>
    <published>2018-08-31T09:12:31.000Z</published>
    <updated>2020-01-18T01:45:05.159Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Java的JVM中的堆和栈"><a href="#Java的JVM中的堆和栈" class="headerlink" title="Java的JVM中的堆和栈"></a>Java的JVM中的堆和栈</h1><ul><li>通常我们定义一个基本数据类型的变量，一个对象的引用，还有就是函数调用的现场保存都使用JVM中的栈空间；</li><li>而通过new关键字和构造器创建的对象则放在堆空间。</li><li>堆是垃圾收集器管理的主要区域，由于现在的垃圾收集器都采用分代收集算法，所以堆空间还可以细分为新生代和老生代，再具体一点可以分为Eden、Survivor（又可分为From Survivor和To Survivor）、Tenured；</li><li>方法区和堆都是各个线程共享的内存区域，用于存储已经被JVM加载的类信息、常量、静态变量、JIT编译器编译后的代码等数据；</li><li>程序中的字面量（literal）如直接书写的100、”hello”和常量都是放在常量池中，常量池是方法区的一部分。</li><li>栈空间操作起来最快但是栈很小，通常大量的对象都是放在堆空间，栈和堆的大小都可以通过JVM的启动参数来进行调整，栈空间用光了会引发StackOverflowError，而堆和常量池空间不足则会引发OutOfMemoryError。</li></ul><h1 id="Java内存分配和垃圾回收"><a href="#Java内存分配和垃圾回收" class="headerlink" title="Java内存分配和垃圾回收"></a>Java内存分配和垃圾回收</h1><p>Java语言中一个显著的特点就是引入了垃圾回收机制，使C++程序员最头疼的内存管理的问题迎刃而解，毕竟C++中的各种构造函数和析构函数能让我们头疼的找不到妈妈。但是既然有了垃圾回收机制，Java的运行效率还是明显的慢于C++，通过这篇文章，我们详细了解Java的内存管理机制与C++的区别，让我们对Java的底层设计更为了解。<br>JVM内存的分配与回收大致可分为如下4个步骤: 何时分配 -&gt; 怎样分配 -&gt; 何时回收 -&gt; 怎样回收.</p><p>一般认为new出来的对象都是被分配在堆上的，其实这个结论不完全正确，因为是大部分new出来的对象被分配在堆上，而不是全部，实际上，还有两个地方可以存放new对象，分别是：栈和TLAB（Thread Local Allocation Buffer）。</p><h1 id="怎样分配-JVM内存分配策略"><a href="#怎样分配-JVM内存分配策略" class="headerlink" title="怎样分配-JVM内存分配策略"></a>怎样分配-JVM内存分配策略</h1><h2 id="Java的堆和栈"><a href="#Java的堆和栈" class="headerlink" title="Java的堆和栈"></a>Java的堆和栈</h2><ul><li>首先明白一点：我们所讨论的Java中的堆(heap)和栈(Stack)，都是JVM内存中的概念，都是指的物理内存memory中的存储空间。不涉及CPU寄存器。</li></ul><h2 id="什么是堆，什么是栈？"><a href="#什么是堆，什么是栈？" class="headerlink" title="什么是堆，什么是栈？"></a>什么是堆，什么是栈？</h2><p>我们先上一张图：<br><img src="/2018/08/31/JAVA中的垃圾回收与内存分配-1/heapAndStack.jpg" alt="heapAndStack"><br><strong>堆</strong> 和栈都是java用来在内存中存放数据的地方，与C++不同的是，java自动管理堆和栈，程序员不能自行设置堆和栈。<br>java中的堆就是运行时存储数据的区域，类的实例对象可以通过new等指令建立从中分配空间。堆是由jvm自动垃圾回收器负责的，堆的优势是可以动态的分配内存大小，存储空间可以自动回收。但是缺点是，由于实在运行时动态进行空间分配，存取速度较慢。<br><strong>栈</strong> 的优势是：存取的速度都比堆要快，仅次于寄存器。栈数据可以共享，但是缺点时，栈空间中的数据大小和生存期必须是确定的，缺乏灵活性。栈主要存放一些基本类型的变量int, short, long, byte, float, double, boolean, char和对象句柄（引用）。</p><p>看到这里，也就明白了一些基础概念：在Java中，基本数据类型的声明和赋值，都是在栈空间中实现的。</p><ul><li>栈就像一个有序序列，而且有个很重要的特殊性，就是存在栈中的数据可以共享：<br>来看下面一个例子：<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">int</span> a = <span class="number">1</span>;</span><br><span class="line"><span class="keyword">int</span> b = <span class="number">1</span>;</span><br><span class="line"><span class="keyword">int</span> c = <span class="number">2</span>;</span><br></pre></td></tr></table></figure></li></ul><p>编译器处理的过程：<br>首先对于第一行，会在栈中创建一个变量，其引用为a，然后查找栈内存中是否有1这个值：<br>（1）如果没有，就给这个变量赋值为1，然后a指向这个变量；<br>（2）如果有，就直接让a直接指向1；<br>所以这段程序，实际上栈中只为两个变量开辟了内存空间，一个存1，一个存2，而a和b都是指向1的引用，c是指向2的引用。</p><ul><li>堆就像它的名字一样，就是一堆！！放在那里，很多很乱~<br>上面的形容可能不是很贴切，但是堆相比于栈而言确实无序很多，大很多，那么堆中存放的都是那些内容呢？<br>我们还是用一段代码来说明：<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Person per = <span class="keyword">new</span> Person();</span><br></pre></td></tr></table></figure></li></ul><p>我们看上面这段代码，在Java中我们常这样写，但是实际上，这段代码包含了两步，分别是：<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">Person per = <span class="keyword">null</span>; <span class="comment">// 声明</span></span><br><span class="line">per = <span class="keyword">new</span> Person(); <span class="comment">// 实例化</span></span><br></pre></td></tr></table></figure></p><p>这样这两部分操作就分别用到了栈空间和堆空间，它们在内存中的划分是这样的：<br><img src="/2018/08/31/JAVA中的垃圾回收与内存分配-1/newPer.png" alt="newPer"><br>堆内存用来存放所有new 创建的对象和 数组的数据，而且它的内存是可以动态调整的，对象的声明周期也不不需要明确。<br>当堆对象对应的栈引用被销毁后，堆对象自然也就变成了无引用状态，也就会被GC回收。这部分内容我们后续会接着介绍。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;Java的JVM中的堆和栈&quot;&gt;&lt;a href=&quot;#Java的JVM中的堆和栈&quot; class=&quot;headerlink&quot; title=&quot;Java的JVM中的堆和栈&quot;&gt;&lt;/a&gt;Java的JVM中的堆和栈&lt;/h1&gt;&lt;ul&gt;
&lt;li&gt;通常我们定义一个基本数据类型的变量，一个
      
    
    </summary>
    
      <category term="Java技术" scheme="https://stonema.github.io/categories/Java%E6%8A%80%E6%9C%AF/"/>
    
    
      <category term="Java" scheme="https://stonema.github.io/tags/Java/"/>
    
  </entry>
  
  <entry>
    <title>CCIS</title>
    <link href="https://stonema.github.io/2018/08/23/CCIS/"/>
    <id>https://stonema.github.io/2018/08/23/CCIS/</id>
    <published>2018-08-23T08:12:21.000Z</published>
    <updated>2020-01-18T01:45:05.152Z</updated>
    
    <content type="html"><![CDATA[<p>休假归来~又要开始忙碌了……纪念一下论文录用，比想象中的easy……但是感觉像是在圈钱啊……这些机构真是……没法说……<br>感觉真正做事情的人很少。。。<br>不管了，自己好好干就行了~</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;休假归来~又要开始忙碌了……纪念一下论文录用，比想象中的easy……但是感觉像是在圈钱啊……这些机构真是……没法说……&lt;br&gt;感觉真正做事情的人很少。。。&lt;br&gt;不管了，自己好好干就行了~&lt;/p&gt;

      
    
    </summary>
    
    
      <category term="随笔" scheme="https://stonema.github.io/tags/%E9%9A%8F%E7%AC%94/"/>
    
  </entry>
  
  <entry>
    <title>WebGL</title>
    <link href="https://stonema.github.io/2018/07/18/WebGL/"/>
    <id>https://stonema.github.io/2018/07/18/WebGL/</id>
    <published>2018-07-18T05:46:17.000Z</published>
    <updated>2020-01-18T01:45:05.181Z</updated>
    
    <content type="html"><![CDATA[<h1 id="WebGL基础与应用"><a href="#WebGL基础与应用" class="headerlink" title="WebGL基础与应用"></a>WebGL基础与应用</h1><p>新的技术啊，没人引导，自己啃的话，一开始的时候真的会觉得无从下手，尤其新的领域的内容，有时会感觉力不从  心，但是相信功夫不负有心人，只有肯努力，一定能在这个领域有所建树的，加油！</p><p>对于webGL，它实际上是OpenGL的web实现，是HTML5标准之下，新出的一套web呈现技术，能够在浏览器端实现以前只有在桌面上才能实现的复杂图形图像。</p><p>通过这篇文章，来介绍学习过程，解决实际问题。<br><strong>这次的问题是：如果将三维模型标准化，归一化，正常的显示在显示器上</strong></p><h2 id="模型矩阵，视图矩阵和投影矩阵"><a href="#模型矩阵，视图矩阵和投影矩阵" class="headerlink" title="模型矩阵，视图矩阵和投影矩阵"></a>模型矩阵，视图矩阵和投影矩阵</h2><p>PS:这部分内容来源于<a href="https://developer.mozilla.org/zh-CN/docs/Web/API/WebGL_API/WebGL_model_view_projection" target="_blank" rel="noopener">model_view_projection</a><br>通常用于表示3D模型对象的三个核心矩阵就是：模型矩阵，视图矩阵，以及投影矩阵。下面我们详细介绍每个矩阵的用途，以及三者的联系。</p><p>空间中点和多边形的基本变换（如平移，缩放和旋转）由各种变换矩阵来处理。这些矩阵可以组合在一起，使它们可用于渲染复杂的3D场景。这些组合矩阵最终将原始模型数据移动到称为 <strong>剪辑空间(Clipspace)</strong> 的特殊坐标空间中。这是一个2单位宽的立方体。中心坐标为（0,0,0），而角点范围为（-1，-1，-1）至（1,1,1）。此剪辑空间被压缩到2d空间并光栅化为图像。</p><ol><li>模型矩阵<br>模型矩阵定义了如何获取原始模型数据，以及如何在三维世界坐标系中移动模型（ which defines how you take your original model data and move it around in 3d world space.）下一步，为了获取世界坐标系中的坐标，以及将模型移动到剪辑空间中（剪辑空间其实就是我们的可视区域），我们需要投影矩阵，而常用于投影的矩阵是透视矩阵（perspective matrix）它模仿的就是照相机的原理。最后如果需要移动相机，就又需要一个视图矩阵，用来移动相机。</li><li>剪辑空间（裁剪空间 Clipspace）<br>剪辑空间也就是我们的可视区域，任何数据位于剪辑空间外的话，则会被剪掉，并且不会渲染。在一个WebGL程序中，模型数据通常会以它自己的坐标系上传到GPU，然后顶点着色器会将这些点转换到不同的坐标系系统下进行渲染。<br><img src="/2018/07/18/WebGL/clip-space-graph.svg" alt="clipspace"><br>上图是所有点必须适合的剪辑空间的可视化。它是2个单位宽，由角（-1，-1，-1）到角（1,1,1）的立方体组成。立方体的中间是点（0,0,0）。<br>这个空间就是剪辑空间或者叫裁剪空间。裁剪空间的目标是能够方便地对渲染图元进行裁剪：完全位于这块空间内部的图元将会被保留，完全位于这块空间外部的图元将会被剔除，而与这块空间边界相交的图元就会被裁剪。。那么，这块空间是如何决定的呢？答案是由视锥体(view frustum)来决定。</li><li><p>两种投影模式<br>视锥体指的是空间中的一块区域，这块区域决定了摄像机可以看到的空间。视锥体由六个平面包围而成，这些平面也被称为 <strong>裁剪平面(clip planes)</strong>。视锥体有两种类型，这涉及两种投影类型：一种是 <strong>正交投影(orthographic projection)</strong>，一种是 <strong>透视投影(perspective projection)</strong>。<br>透视投影:<br><img src="/2018/07/18/WebGL/perspective_projection.png" alt="透视投影"></p><p>正交投影:<br><img src="/2018/07/18/WebGL/orthographic_projection.png" alt="正交投影"></p></li></ol><h2 id="世界坐标系（World-Coordinate-System）"><a href="#世界坐标系（World-Coordinate-System）" class="headerlink" title="世界坐标系（World Coordinate System）"></a>世界坐标系（World Coordinate System）</h2><p>世界坐标系，我们可以看做是一个永恒不变的参考系，所以的其他模型，和各种坐标系都以这个坐标系作为基准。世界坐标系的位置不随模型的变化而改变。</p><h2 id="模型坐标系-Model-Coordinate-System"><a href="#模型坐标系-Model-Coordinate-System" class="headerlink" title="模型坐标系 (Model Coordinate System)"></a>模型坐标系 (Model Coordinate System)</h2><p>模型坐标系是建模时所用到的坐标系，模型的原点为(0,0,0),但是它可以是世界坐标系中的任意一点。<br>通常在<code>Three.js</code>中，我们设置<code>Object.position.set(0,0,0)</code>就是将模型的原点设置为世界坐标系的原点。</p><ul><li>模型中心设置<br>  <code>object.children[i].geometry.center(); //将网格模型的中心移动到世界坐标系的中心</code> 这样做，对于单一Mesh构成的三维模型能够轻松将模型移动到世界坐标系中央，但是对于多Mesh构成的模型来讲，每个children的Mesh都会被移动到World坐标系原点。</li></ul><h2 id="如何将加载后处于偏移位置的模型移动到坐标系原点呢？"><a href="#如何将加载后处于偏移位置的模型移动到坐标系原点呢？" class="headerlink" title="如何将加载后处于偏移位置的模型移动到坐标系原点呢？"></a>如何将加载后处于偏移位置的模型移动到坐标系原点呢？</h2><p><img src="/2018/07/18/WebGL/original.png" alt="原始图"><br>可以看到上图中的模型，虽然模型坐标系和世界坐标系重合，但是模型的原点却位于三维物体的一个角落，看起来不美观。我们起初的办法是通过设置<code>object.children[i].geometry.center()</code>将三维物体的中心移动到模型坐标系原点，但是刚好上图中的模型是单个Mesh构成的三维物体，所以没有发现问题，当使用多Mesh三维模型的时候，上面的方法就会把所有的Mesh移动的模型坐标系中心，使得模型的Mesh混乱，无法显示原来的样子。<br><img src="/2018/07/18/WebGL/building.png" alt="Mesh混乱"></p><p>为了修复这个问题，想到的解决办法是：计算三维模型AABB包围盒两个对角点的位置坐标相应方向和的均值，得到的均值后，将模型的position设置到这个点，从而达到将三维物体中心放置到坐标系原点的目的。</p><ol><li><p>加载三维模型</p> <figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">objLoader = <span class="keyword">new</span> THREE.OBJLoader();</span><br><span class="line">objLoader.setPath(<span class="string">'./obj/'</span>);</span><br><span class="line">objLoader.load(<span class="string">'a.obj'</span>, <span class="function"><span class="keyword">function</span> (<span class="params">object</span>) </span>&#123;</span><br><span class="line">oneObj = object;</span><br><span class="line">object.traverse(<span class="function"><span class="keyword">function</span> (<span class="params">child</span>) </span>&#123;</span><br><span class="line">    <span class="keyword">if</span> (child.type === <span class="string">"Mesh"</span>) &#123;</span><br><span class="line">        child.geometry.computeBoundingBox();</span><br><span class="line">        child.geometry.verticesNeedUpdate = <span class="literal">true</span>;</span><br><span class="line">        child.material.side = THREE.DoubleSide;</span><br><span class="line">        <span class="comment">//child.geometry.center(); //设置模型中心点为几何体的中心</span></span><br><span class="line">    &#125;</span><br><span class="line">&#125;);</span><br><span class="line">&#125;);</span><br></pre></td></tr></table></figure></li><li><p>构造AABB包围盒</p> <figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">box = <span class="keyword">new</span> THREE.BoxHelper(object);</span><br></pre></td></tr></table></figure></li><li><p>计算包围盒任意两个对角点的均值，并移动模型</p> <figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">var</span> points = box.geometry.attributes.position.array;</span><br><span class="line">obj_x = (points[<span class="number">0</span>]+points[<span class="number">18</span>])/<span class="number">2</span>;</span><br><span class="line">obj_y = (points[<span class="number">1</span>]+points[<span class="number">19</span>])/<span class="number">2</span>;</span><br><span class="line">obj_z = (points[<span class="number">2</span>]+points[<span class="number">20</span>])/<span class="number">2</span>;</span><br><span class="line">oneObj.position.set(-obj_x,-obj_y,-obj_z); <span class="comment">//这是移动模型时要反向移动</span></span><br></pre></td></tr></table></figure></li></ol><p><img src="/2018/07/18/WebGL/moveBuilding.png" alt="moving"></p><p>这样，就解决了模型便宜的问题，但是模型的大小适配问题还在，我们的思路是：获取到模型表面的距离最远的两个点，然后保证这个距离是小于<code>camera</code>的<code>far-near</code>的，同时这个长度大于<code>far-near</code> x 倍，就相应缩小 n*x倍，n是个放大系数，这里我取值是20。<br>实现过程如下：</p><figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br></pre></td><td class="code"><pre><span class="line">    <span class="comment">// 获取三维模型表面点的最大距离</span></span><br><span class="line">    <span class="keyword">var</span> box3 = <span class="keyword">new</span> THREE.Box3();</span><br><span class="line">    box3.setFromObject(object);</span><br><span class="line">    <span class="keyword">var</span> maxLength = box3.getSize(<span class="keyword">new</span> THREE.Vector3()).length();</span><br><span class="line">    <span class="keyword">var</span> consult = (camera.far - camera.near) / (<span class="number">20</span>*maxLength);</span><br><span class="line">    <span class="comment">//写入场景内</span></span><br><span class="line">    <span class="keyword">var</span> currentScale = consult;</span><br><span class="line">    object.scale.set(currentScale,currentScale,currentScale);</span><br><span class="line"><span class="string">``</span><span class="string">` </span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">## 实现过程</span></span><br><span class="line"><span class="string">完整实现过程：</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">`</span><span class="string">``</span>javascript</span><br><span class="line">        <span class="comment">//  objLoader</span></span><br><span class="line">        objLoader = <span class="keyword">new</span> THREE.OBJLoader();</span><br><span class="line">        objLoader.setPath(<span class="string">'./obj/'</span>);</span><br><span class="line">        objLoader.load(<span class="string">'a.obj'</span>, <span class="function"><span class="keyword">function</span> (<span class="params">object</span>) </span>&#123;</span><br><span class="line">            oneObj = object;</span><br><span class="line">            object.traverse(<span class="function"><span class="keyword">function</span> (<span class="params">child</span>) </span>&#123;</span><br><span class="line">                <span class="keyword">if</span> (child.type === <span class="string">"Mesh"</span>) &#123;</span><br><span class="line">                    child.geometry.computeBoundingBox();</span><br><span class="line">                    child.geometry.verticesNeedUpdate = <span class="literal">true</span>;</span><br><span class="line">                    child.material.side = THREE.DoubleSide;</span><br><span class="line">                    <span class="comment">//child.geometry.center(); //设置模型中心点为几何体的中心</span></span><br><span class="line">                &#125;</span><br><span class="line">            &#125;);</span><br><span class="line">            object.name = <span class="string">"zxj"</span>;  <span class="comment">//设置模型的名称</span></span><br><span class="line">            <span class="comment">//对模型的大小进行调整</span></span><br><span class="line">            <span class="comment">// object.scale.x =0.001;</span></span><br><span class="line">            <span class="comment">// object.scale.y =0.001;</span></span><br><span class="line">            <span class="comment">// object.scale.z =0.001;</span></span><br><span class="line">            <span class="comment">//object.lookAt(new THREE.Vector3(0,0,0));</span></span><br><span class="line">            <span class="comment">// 加入模型的aabb包围盒</span></span><br><span class="line">            <span class="comment">// 获取三维模型表面点的最大距离</span></span><br><span class="line">            <span class="keyword">var</span> box3 = <span class="keyword">new</span> THREE.Box3();</span><br><span class="line">            box3.setFromObject(object);</span><br><span class="line">            <span class="keyword">var</span> maxLength = box3.getSize(<span class="keyword">new</span> THREE.Vector3()).length();</span><br><span class="line">            <span class="keyword">var</span> consult = (camera.far - camera.near) / (<span class="number">20</span>*maxLength);</span><br><span class="line">            <span class="comment">//写入场景内</span></span><br><span class="line">            <span class="keyword">var</span> currentScale = consult;</span><br><span class="line">            object.scale.set(currentScale,currentScale,currentScale);</span><br><span class="line">            box = <span class="keyword">new</span> THREE.BoxHelper(object);</span><br><span class="line">            <span class="comment">// box.material.transparents = true;</span></span><br><span class="line">            <span class="comment">// box.material.depthTest = false;</span></span><br><span class="line">            <span class="comment">// box.visible = true;</span></span><br><span class="line">            <span class="keyword">var</span> points = box.geometry.attributes.position.array;</span><br><span class="line">            obj_x = (points[<span class="number">0</span>]+points[<span class="number">18</span>])/<span class="number">2</span>;</span><br><span class="line">            obj_y = (points[<span class="number">1</span>]+points[<span class="number">19</span>])/<span class="number">2</span>;</span><br><span class="line">            obj_z = (points[<span class="number">2</span>]+points[<span class="number">20</span>])/<span class="number">2</span>;</span><br><span class="line">            oneObj.position.set(-obj_x,-obj_y,-obj_z);</span><br><span class="line">            <span class="comment">//scene.add(box);</span></span><br><span class="line">            scene.add(object);</span><br><span class="line">        &#125;);</span><br></pre></td></tr></table></figure><h1 id="裁剪空间-clipspace"><a href="#裁剪空间-clipspace" class="headerlink" title="裁剪空间(clipspace)"></a>裁剪空间(clipspace)</h1><p> 顶点接下来要从观察空间转换到裁剪空间(clip space，也被称为齐次裁剪空间)中，这个用于转换的矩阵叫做裁剪矩阵(clip matrix)，也被称为投影矩阵(projection matrix)。如上面的图所示，裁剪空间是由6个面构成的棱台，它就是webGL中的视锥体，对于这个视锥而言，近平面和远平面分别是近裁剪平面(near clip plane)和远裁剪平面(far clip plane)。裁剪空间的作用就是对存在于视锥体内部的顶点进行渲染，如果不在视锥体内，就裁减掉，不进行渲染。<br> 由此，我们引入一个新的概念：<strong>投影矩阵</strong><br> 试想一下，对于这个视锥体而言，如果我们想判断一个点是否在视锥体内部是比较麻烦的，因为视锥体的边界计算就是个复杂的活，那么投影矩阵就是这么一种工具，能够方便的对三维模型的点进行映射，通过结果判断顶点是否位于模型内部。</p><h2 id="投影矩阵有两个目的："><a href="#投影矩阵有两个目的：" class="headerlink" title="投影矩阵有两个目的："></a>投影矩阵有两个目的：</h2><ol><li>首先是为投影做准备。这是个迷惑点，虽然投影矩阵的名称包含了投影二字，但是它并没有进行真正的投影工作，而是在为投影做准备。真正的投影发生在后面的 <strong>齐次除法(homogeneous division)</strong> 过程中。而经过投影矩阵的变换后，顶点的 <strong>w</strong> 分量将会具有特殊的意义。</li><li>其次是对x、y、z分量行进缩放。我们上面讲过直接使用视锥体的6个裁剪平面来进行裁剪会比较麻烦。而经过投影矩阵的缩放后，我们可以直接使用w分量作为一个范围值，如果x、y、z分量都位于这个范围内，就说明该顶点位于裁剪空间内。</li></ol><p>在裁剪空间之前，虽然我们使用了齐次坐标来表示点和矢量，但它们的第四个分量都是固定的：点的w分量是1，方向矢量的w分量是0。经过投影矩阵的变换后，我们就会赋予齐次坐标的第4个坐标更加丰富的含义。下面，我们来看一下透视投影使用的投影矩阵具体是什么。</p><h3 id="透视投影"><a href="#透视投影" class="headerlink" title="透视投影"></a>透视投影</h3><p><img src="/2018/07/18/WebGL/fov.png" alt="fov"><br>视锥体的意义在于定义了场景中的一块三维空间。所有位于这块空间内的物体将会被渲染，否则就会被剔除或裁剪。我们已经知道，这块区域由6个裁剪平面定义，那么这6个裁剪平面又是怎么决定的呢？它们由Camera组件中的参数和Game视图的横纵比共同决定。<br>我们可以通过Camera组件的Field of View(简称FOV)属性来改变视锥体竖直方向的张开角度，而Clipping Planes中的Near和Far参数可以控制视锥体的近裁剪平面和远裁剪平面距离摄像机的远近。这样，我们可以求出视锥体近裁剪平面和远裁剪平面的高度，也就是：   </p><p>$nearClipPaneHeight = 2<em>Near</em>tan(FOV/2)$<br>$farClipPlaneHeight = 2<em>Far</em>tan(FOV/2)$</p><p>现在我们还缺乏横向的信息。这可以通过摄像机的横纵比得到。假设，当前摄像机的横纵比为Aspect，我们定义：</p><p>$Aspect = nearClipPlaneWidth/nearClipPlaneHeight$<br>$Aspect = farClipPlaneWidth/farClipPlaneHeight$</p><p>现在，我们可以根据已知的Near、Far、FOV和Aspect的值来确定透视投影的投影矩阵。如下：<br><em>投影矩阵</em><br><img src="/2018/07/18/WebGL/perspectiveMatrix.png" alt="投影矩阵"><br>需要注意的是，这里的投影矩阵是建立在WebGL,Unity等对坐标系的假定上面的，也就是说，我们针对的是观察空间为 <strong>右手坐标系</strong>，使用列矩阵在矩阵右侧进行相乘，且变换后z分量范围将在[-w, w]之间的情况。而在类似DirectX这样的图形接口中，它们希望变换后z分量范围将在[0, w]之间，因此就需要对上面的透视矩阵进行一些更改。<br>而一个顶点和上述投影矩阵相乘后，可以由观察空间变换到裁剪空间中，结果如下：<br><img src="/2018/07/18/WebGL/Perspective.png" alt="result"></p><p>从结果可以看出，这个投影矩阵本质就是对x、y和z分量进行了不同程度的缩放(当然，z分量还做了一个平移)，缩放的目的是为了方便裁剪。我们可以注意到，此时顶点的w分量不再是1，而是原先z分量的取反结果。现在，我们就可以按如下不等式来判断一个变换后的顶点是否位于视锥体内。如果一个顶点在视锥体内，那么它变换后的坐标必须满足：</p><script type="math/tex; mode=display">-w <= x <= w \\-w <= y <= w \\-w <= z <= w \\</script><p>任何不满足上述条件的图元都需要被剔除或者裁剪。</p><h1 id="投影矩阵的推导"><a href="#投影矩阵的推导" class="headerlink" title="投影矩阵的推导"></a>投影矩阵的推导</h1><h2 id="什么是投影？"><a href="#什么是投影？" class="headerlink" title="什么是投影？"></a>什么是投影？</h2><p>在理解投影之前，我们要知道一些知识：计算机屏幕是一个二维图像的展示区域，并不能真正的展示三维的物体，最终的形式还是要以二维平面的形式来展示三维物体，那么也就涉及到了三维物体的二维投影，所以现有的各类图形学库，比如OpenGL，Direct3D 都是研究如何把三维模型转换成二维图像进行渲染方面的工作，这也就是投影的过程。一个简单的例子就是：把3D物体对象投影到2D表面的方法是简单的把没个坐标点的 <code>Z</code>坐标丢弃，对立方体来说，看上去就如下图所示：<br><img src="/2018/07/18/WebGL/3dproj01.gif" alt="Figure 1: Projection onto the xy plane by discarding z-coordinates." title="图1：通过丢弃Z坐标投影到XY平面"></p><p>当然，这种方式是过于简单的，大部分时候不是特别有用。因为大部分不会单纯的舍掉 <code>Z</code> 坐标。而是利用<code>Z</code>坐标来做深度视觉缓冲和可见度方面的工作。<br>投影公式的作用是将你的几何体变换到一个新的空间体中，这个空间体称为：规范视域体（canonical view volume），规范视域体的精确坐标可能在不同的图形API之间互不相同，但作为讨论起见，把它认为是从(-1, -1, 0)延伸至(1, 1, 1)的盒子，这也是Direct3D中使用的。对于映射到视域体内部的模型而言，它们的<code>x</code>和<code>y</code>坐标被用于映射到屏幕上。这并不代表<code>z</code>坐标是无用的，我们前面提到它通常被深度缓冲用于可见度测试。这就是为什么变换到一个新的空间体中，而不是投影到一个平面上。</p><h2 id="正交投影"><a href="#正交投影" class="headerlink" title="正交投影"></a>正交投影</h2><p><img src="/2018/07/18/WebGL/3dproj02.gif" alt="Orthographic Projection" title="图2：正交投影"><br>正交投影如上图所示，正如我们看到的，坐标的原点在 <strong>规范视域体</strong> 的左表面上，而视域体由6个面定义：<br>left:x = l;<br>right:x = r;<br>bottom:y = b;<br>top:y = t;<br>near:z = n;<br>far:z = f<br>因为视域体和规范视域体都是轴对齐盒子，这种类型的投影没有距离更正。最终的结果是，事实上，很像图1那样每个坐标点只是丢弃了z坐标。正交投影常使用在特定的场景中，比如下图的视图投影：<br><img src="/2018/07/18/WebGL/3dproj04.gif" alt="样例" title="图3：正交投影-样例"><br>而对于第一人称射击类的游戏，这种正交投影的方式是不可行的。试想一下在不知道任何东西有多远的情况下玩！<br>所以，我们要弄清楚视域体是如何投影到规范视域体的，最简单的方法可能是3个坐标轴分开考虑，并且计算如何沿着每个坐标轴将点从视域体映射到规范视域体。再来看一下我们前面的视域体的6个面的表示形式：</p><script type="math/tex; mode=display">    left:x = l; \\    right:x = r; \\    bottom:y = b; \\    top:y = t; \\    near:z = n; \\    far:z = f \\</script><p>从<code>x</code>轴的坐标开始变换，对于视域体而言，<code>x</code>的范围是：所以说而我们的目的是将这个视域体变换到$[-1, 1]$:<br>$l \leq x \leq r$现在，我们的目标是把这个范围缩小到我们期望的$[-1,1]$,所以，第一步：各项减去$l$,这样，左边就变成了0，$0 \leq x-l \leq r-l$ 现在，范围的一段就是0，而我们希望的范围宽度是2个单位，从-1到1，所以把各项乘以$\frac{2}{r-l}$。也就得到了：$0 \leq \frac{2x-2l}{r-l} \leq 2$，下一步各项减去1也就得到了规范视域体的范围$[-1,1]$，</p><script type="math/tex; mode=display">-1 \leq \frac{2x-2l}{r-l} -1 \leq 1</script><p>变换一下，可以写成：</p><script type="math/tex; mode=display">-1 \leq \frac{2x-r-l}{r-l}</script><p>最后，把中间项分成两部分使它形如px+q的形式，我们需要把项组织成这种形式这样我们推导的公式就可以简单的转换成矩阵形式：</p><script type="math/tex; mode=display">-1 \leq \frac{2x}{r-l}-\frac{r+l}{r-l} \leq 1</script><p>这个不等式的中间项告诉了我们把x转换到规范视域体的公式：</p><script type="math/tex; mode=display">x'=\frac{2x}{r-l}-\frac{r+l}{r-l}</script><p>同样对于y进行坐标变换可以得到：</p><script type="math/tex; mode=display">y' = \frac{2y}{t-b}-\frac{t+b}{t-b}</script><p>最后，需要推倒z的变换公式。<code>z</code>的推导有点不同，因为需要把<code>z</code>映射到范围$[0, 1]$而不是$[-1, 1]$，但看上去很相似。<br><code>z</code>坐标在视域体中最开始在范围<script type="math/tex">[n,f]</script>把各项减去$n$，就变成$0 \leq z-n \leq f-n$ 现在剩余要做的就是除以 $f-n$，这样就产生了最终的范围$[0,1]$。和前面相同，注意$f-n$,这样就产生了最终的范围$[0,1]$：</p><script type="math/tex; mode=display">0\leq \frac{z-n}{f-n} \leq 1</script><p>这样便给出了<code>z</code>的变换公式：</p><script type="math/tex; mode=display">z' = \frac{z}{f-n}-\frac{n}{f-n}</script><p>现在，可以准备正交投影矩阵了。总结到目前为止的工作，推导了3个投影公式：</p><script type="math/tex; mode=display">x' = \frac{2x}{r-l}-\frac{r+l}{r-l}</script><script type="math/tex; mode=display">y' = \frac{2y}{t-b}-\frac{t+b}{t-b}</script><script type="math/tex; mode=display">z' = \frac{z}{f-n}-\frac{n}{f-n}</script><p>写成矩阵形式：</p><script type="math/tex; mode=display">P_{0} =  \left[\begin{matrix}   \frac{2}{r-l} & 0 & 0 & -\frac{r+l}{r-l} \\   0 & \frac{2}{t-b} & 0 & -\frac{t+b}{t-b} \\   0 & 0 & \frac{1}{f-n} & -\frac{n}{f-n} \\   0 & 0 & 0 & 1\end{matrix}\right]\left[\begin{matrix}   x\\   y \\   z\\   1\end{matrix}\right]</script><p>考虑几点: 首先，在可见空间中，摄像机定位在原点并且沿着z轴方向观看。第二，你通常希望你的视野在左右方向上延伸的同样远，并且在z轴的上下方向上也延伸的同样远。如果是这样的情况，那么z轴正好直接穿过你视域体的的中心，所以得到了r = -l并且t = -b。换句话说，你可以把r, l, t和b一起忘掉，简单的把视域体定义为1个宽度w和1个高度h，以及裁剪面f和n。如果你在正交投影矩阵中应用上面说的，那么你将得到这个相当简化的版本：</p><script type="math/tex; mode=display">P_{0} = \left[ \begin{matrix}   \frac{2}{w} & 0 & 0 & -\frac{r+l}{r-l} \\   0 & \frac{2}{h} & 0 & -\frac{t+b}{t-b} \\   0 & 0 & \frac{1}{f-n} & -\frac{n}{f-n} \\   0 & 0 & 0 & 1  \end{matrix}  \right]</script><p>而其实上面的矩阵可以用两个简单的变换串联替代：平移其次是缩放。如果你思考几何的话这对你是有意义的，因为所有你在正交投影中做的就是从一个轴对齐盒子转向另一个轴对齐盒子；视域体不改变它的形状，只改变它的位置和大小。具体来说：</p><script type="math/tex; mode=display">P_{0}=ST=\left[ \begin{matrix}   \frac{2}{r-l} & 0 & 0 & 0 \\   0 & \frac{2}{t-b} & 0 & 0 \\   0 & 0 & \frac{1}{f-n} &0 \\   0 & 0 & 0 & 1  \end{matrix}  \right]\left[ \begin{matrix}   1 & 0 & 0 & 0 \\   0 & 1 & 0 & 0 \\   0 & 0 & 1 & -n \\   0 & 0 & 0 & 1  \end{matrix}  \right]</script><h2 id="透视投影-1"><a href="#透视投影-1" class="headerlink" title="透视投影"></a>透视投影</h2><p>对于透视投影，思想是一样的，但过程略复杂，慢慢再更新<br><img src="/2018/07/18/WebGL/3dproj22.gif" alt="Perspective Projection" title="图4：透视投影"><br><img src="/2018/07/18/WebGL/透视投影视图.png" alt="" title="图5: 使用相似三角形投影一个点到z=n平面"></p><script type="math/tex; mode=display">x'z = \frac{2n}{r-l}x-\frac{r+l}{r-l}z \\y'z = \frac{2n}{t-b}y-\frac{t+b}{t-b}z \\z'z=\frac{f}{f-n}z=\frac{fn}{f-n} \\w'z=z</script><p>而后得到矩阵表示：</p><script type="math/tex; mode=display">P_{y}=\left[ \begin{matrix}   \frac{2n}{r-l} & 0 & -\frac{r+l}{r-l} & 0 \\   0 & \frac{2n}{t-b} & -\frac{t+b}{t-b} & 0 \\   0 & 0 & \frac{f}{f-n} & -\frac{fn}{f-n} \\   0 & 0 & 1 & 0  \end{matrix}  \right]</script><p>如果你假设视域体是对称的并且中心是z轴(也就是r = -l，t = -b)，你可以简单的用视域体的宽w和高h改写矩阵中的各项：</p><script type="math/tex; mode=display">P_{y}=\left[ \begin{matrix}   \frac{2n}{w} & 0 & 0 & 0 \\   0 & \frac{2n}{h} & 0 & 0 \\   0 & 0 & \frac{f}{f-n} & -\frac{fn}{f-n} \\   0 & 0 & 1 & 0  \end{matrix}  \right]</script><p><img src="/2018/07/18/WebGL/3dproj38.gif" alt="view frustum" title="图6: 视域体的高由垂直可视范围的角度a定义"></p><h1 id="参考："><a href="#参考：" class="headerlink" title="参考："></a>参考：</h1><p>部分来自如下文章，感谢作者的勤劳付出。<br><a href="http://www.devacg.com/?post=522" target="_blank" rel="noopener">裁剪空间-追风剑情</a><br><a href="https://developer.mozilla.org/zh-CN/docs/Web/API/WebGL_API" target="_blank" rel="noopener">WebGL</a><br><a href="https://www.codeguru.com/cpp/misc/misc/graphics/article.php/c10123/Deriving-Projection-Matrices.htm" target="_blank" rel="noopener">What Is Projection</a></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;WebGL基础与应用&quot;&gt;&lt;a href=&quot;#WebGL基础与应用&quot; class=&quot;headerlink&quot; title=&quot;WebGL基础与应用&quot;&gt;&lt;/a&gt;WebGL基础与应用&lt;/h1&gt;&lt;p&gt;新的技术啊，没人引导，自己啃的话，一开始的时候真的会觉得无从下手，尤其新的领
      
    
    </summary>
    
      <category term="图形学" scheme="https://stonema.github.io/categories/%E5%9B%BE%E5%BD%A2%E5%AD%A6/"/>
    
    
      <category term="前端" scheme="https://stonema.github.io/tags/%E5%89%8D%E7%AB%AF/"/>
    
      <category term="Three.js" scheme="https://stonema.github.io/tags/Three-js/"/>
    
      <category term="webgl" scheme="https://stonema.github.io/tags/webgl/"/>
    
  </entry>
  
  <entry>
    <title>考试院.net项目技术总结</title>
    <link href="https://stonema.github.io/2018/07/10/%E8%80%83%E8%AF%95%E9%99%A2-net%E9%A1%B9%E7%9B%AE%E6%8A%80%E6%9C%AF%E6%80%BB%E7%BB%93/"/>
    <id>https://stonema.github.io/2018/07/10/考试院-net项目技术总结/</id>
    <published>2018-07-10T01:29:08.000Z</published>
    <updated>2020-01-18T01:45:05.210Z</updated>
    
    <content type="html"><![CDATA[<p>开发考试院笔迹鉴别系统的过程中遇到了很多的问题，也学到了很多，将其记录下来。以供今后回顾。<br><strong>Warning:</strong>项目构建和项目打开的时候一定要使用解决方法，不要使用网站！一定要使用解决方法，不要使用网站！一定要使用解决方法，不要使用网站！重要的事情说三遍！！！网站项目是给静态web项目用的。使用解决方法打开项目，才能每次生成项目的时候把dll更新到最新的状态。</p><h1 id="数据库连接方式"><a href="#数据库连接方式" class="headerlink" title="数据库连接方式"></a>数据库连接方式</h1><p>这个最好实时跟着Oracle的官方文档走，我使用的是<code>Oracle.ManagerdDataAccess</code>,把它下载后加入到项目的引用。<br>Web.config文件的配置如下：<br><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">&lt;!-- 本地 --&gt;</span></span><br><span class="line"><span class="comment">&lt;!--&lt;add name="Oracle_DB" connectionString="DATA SOURCE=127.0.0.1/orcl;PASSWORD=bjshadmin;USER ID=ZK" providerName="Oracle.ManagedDataAccess.Client"/&gt;--&gt;</span></span><br><span class="line"><span class="comment">&lt;!-- 远程 --&gt;</span></span><br></pre></td></tr></table></figure></p><p>配置完成后，我们在后台程序中就可以用下面的方式调用数据库连接和方法：<br><figure class="highlight csharp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//创建连接字符串</span></span><br><span class="line">String connctionString = ConfigurationManager.ConnectionStrings[<span class="string">"Oracle_DB"</span>].ToString();</span><br><span class="line">OracleConnection conn = <span class="keyword">new</span> OracleConnection(connctionString); <span class="comment">//创建连接</span></span><br><span class="line">OracleCommand cmd = conn.CreateCommand();<span class="comment">// 创建数据库控制器</span></span><br><span class="line">cmd.CommandText = <span class="string">"SELECT * FROM table"</span>;<span class="comment">//设置commandText</span></span><br><span class="line">conn.Open();<span class="comment">//开启连接</span></span><br><span class="line"><span class="comment">/****************查询语句的执行方法 begin******************/</span></span><br><span class="line">OracleDataReader reader = cmd.ExecuteReader(); <span class="comment">//至此查询结果接收到了reader对象中</span></span><br><span class="line"><span class="comment">//读取reader对象中的值。</span></span><br><span class="line"><span class="keyword">while</span> (reader.Read())</span><br><span class="line">&#123;</span><br><span class="line">    StuInfo stu = <span class="keyword">new</span> StuInfo();</span><br><span class="line">    stu.Ks_zkz = reader[<span class="number">0</span>].ToString();</span><br><span class="line">    stu.Ks_xm  = reader[<span class="number">1</span>].ToString();</span><br><span class="line">    stuList.Add(stu);</span><br><span class="line">&#125; </span><br><span class="line"><span class="comment">/*************** 执行Update语句的方法 ******************/</span> </span><br><span class="line"><span class="keyword">int</span> rows = cmd.ExecuteNonQuery(); <span class="comment">//返回受影响条数，删除与增加语句类似</span></span><br><span class="line"></span><br><span class="line">conn.close();<span class="comment">//最后不要忘了close连接</span></span><br></pre></td></tr></table></figure></p><h1 id="aspx页面中处理JS的Ajax请求"><a href="#aspx页面中处理JS的Ajax请求" class="headerlink" title="aspx页面中处理JS的Ajax请求"></a>aspx页面中处理JS的Ajax请求</h1><p>aspx页面中处理JS的Ajax请求时可以使用<code>ashx</code>, <em>右键-&gt;添加-&gt;一般处理程序</em>,一般处理程序可以充当服务器端处理Ajax请求的文件：</p><p>JS：<br><figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//通过审核的处理</span></span><br><span class="line"><span class="function"><span class="keyword">function</span> <span class="title">passStu_next</span>(<span class="params"></span>) </span>&#123;</span><br><span class="line">    <span class="keyword">var</span> zkzh = $(<span class="string">'.kszkz'</span>).val();</span><br><span class="line">    alert(<span class="string">"标记学号:"</span> + zkzh + <span class="string">"已通过审核"</span>);</span><br><span class="line">    $.ajax(&#123;</span><br><span class="line">        type: <span class="string">"post"</span>,</span><br><span class="line">        url: <span class="string">"passAndNextHandler.ashx"</span>,</span><br><span class="line">        data: &#123; <span class="string">"kszkz"</span>: zkzh &#125;,</span><br><span class="line">        success: <span class="function"><span class="keyword">function</span> (<span class="params">result</span>) </span>&#123;</span><br><span class="line">            <span class="comment">//跳转到下一个考生的详细内容页面</span></span><br><span class="line">            <span class="keyword">if</span> (result == <span class="string">""</span>) &#123;</span><br><span class="line">                alert(<span class="string">"审核完毕"</span>);</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="keyword">else</span> &#123;</span><br><span class="line">                <span class="built_in">window</span>.location.href = <span class="string">"DetailCardsInfo.aspx?zkzh="</span> + result;</span><br><span class="line">            &#125;</span><br><span class="line">            </span><br><span class="line">        &#125;,</span><br><span class="line">        error: <span class="function"><span class="keyword">function</span> (<span class="params">result</span>) </span>&#123;</span><br><span class="line">            alert(<span class="string">"error"</span>);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><p>ashx程序：<br><figure class="highlight csharp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br></pre></td><td class="code"><pre><span class="line">public class passAndNextHandler : IHttpHandler, IRequiresSessionState</span><br><span class="line">&#123;</span><br><span class="line">    <span class="comment">//创建连接字符串</span></span><br><span class="line">    String connctionString = ConfigurationManager.ConnectionStrings[<span class="string">"Oracle_DB"</span>].ToString();</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">ProcessRequest</span>(<span class="params">HttpContext context</span>)</span></span><br><span class="line"><span class="function">    </span>&#123;</span><br><span class="line">        <span class="keyword">string</span> czr = HttpContext.Current.Session[<span class="string">"UserName"</span>].ToString();</span><br><span class="line">        String nextZkz = <span class="literal">null</span>;</span><br><span class="line">        context.Response.ContentType = <span class="string">"text/plain"</span>;</span><br><span class="line">        String zkzh = context.Request.Form[<span class="string">"kszkz"</span>];</span><br><span class="line">        String sql = <span class="string">"UPDATE ZK.V_BYSQ_BJSH_SKB_KS SET BJSH_JG_SKB = '1',BJSH_SKB_CZR='"</span> + czr + <span class="string">"' WHERE KS_ZKZ= '"</span> + zkzh + <span class="string">"'"</span>;</span><br><span class="line">        OracleConnection conn = <span class="keyword">new</span> OracleConnection(connctionString);</span><br><span class="line">        OracleCommand cmd = conn.CreateCommand();</span><br><span class="line">        conn.Open();</span><br><span class="line">        <span class="comment">//向表中插入数据的同时，选择下一个考生</span></span><br><span class="line">        OracleTransaction transaction = conn.BeginTransaction(IsolationLevel.ReadCommitted);</span><br><span class="line">        cmd.Transaction = transaction; <span class="comment">//开始事务</span></span><br><span class="line">        <span class="keyword">try</span></span><br><span class="line">        &#123;</span><br><span class="line">            cmd.CommandText = sql1;</span><br><span class="line">            cmd.ExecuteNonQuery();</span><br><span class="line">            <span class="comment">//提交事务</span></span><br><span class="line">            transaction.Commit(); <span class="comment">//这里如果是多条语句，同时提交成功才返回</span></span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">catch</span> (Exception ex)</span><br><span class="line">        &#123;</span><br><span class="line">            transaction.Rollback(); <span class="comment">//未成功就rollback</span></span><br><span class="line">            Console.Write(ex.ToString());</span><br><span class="line">        &#125;</span><br><span class="line">        context.Response.Write(nextZkz);</span><br><span class="line">        conn.Close();</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">bool</span> IsReusable</span><br><span class="line">    &#123;</span><br><span class="line">        <span class="keyword">get</span></span><br><span class="line">        &#123;</span><br><span class="line">            <span class="keyword">return</span> <span class="literal">false</span>;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><h1 id="访问网络路径中的文件，以及下载文件到本地。"><a href="#访问网络路径中的文件，以及下载文件到本地。" class="headerlink" title="访问网络路径中的文件，以及下载文件到本地。"></a>访问网络路径中的文件，以及下载文件到本地。</h1><ol><li><p>在本地磁盘创建存储路径：</p> <figure class="highlight csharp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">String directoryPath = <span class="string">@"D:\Downloadimgs\"</span>+list_zkz[i]+<span class="string">"//"</span>; <span class="comment">//定义一个路径变量</span></span><br><span class="line"><span class="keyword">if</span> (!Directory.Exists(directoryPath))<span class="comment">//如果路径不存在</span></span><br><span class="line">&#123;</span><br><span class="line">    Directory.CreateDirectory(directoryPath);<span class="comment">//创建一个路径的文件夹</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li><li><p>网络路径的映射以及文件拷贝</p> <figure class="highlight csharp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//设置源目标路径</span></span><br><span class="line"><span class="keyword">string</span> sourceFile = <span class="string">@"http://127.0.0.1/img//"</span> + reader[<span class="number">0</span>] + <span class="string">"//"</span> + reader[<span class="number">1</span>].ToString().Trim() + <span class="string">"//"</span> + reader[<span class="number">3</span>].ToString().Trim() + <span class="string">".jpg"</span>;</span><br><span class="line"><span class="comment">//设置目的地路径</span></span><br><span class="line"><span class="keyword">string</span> destinationFile = <span class="string">@"D:\Downloadimgs\"</span> + list_zkz[i] + <span class="string">"//"</span> + reader[<span class="number">2</span>] + <span class="string">"_"</span> + reader[<span class="number">1</span>].ToString().Trim() + <span class="string">"_"</span> + reader[<span class="number">0</span>] + <span class="string">".jpg"</span>;</span><br><span class="line"><span class="comment">//FileInfo file = new FileInfo(sourceFile);</span></span><br><span class="line"><span class="comment">//下面的这种文件拷贝方式，只能用于本地磁盘的文件拷贝，不能用于网络dowmload</span></span><br><span class="line"><span class="comment">//if (file.Exists)</span></span><br><span class="line"><span class="comment">//&#123;</span></span><br><span class="line"><span class="comment">//    // true is overwrite</span></span><br><span class="line"><span class="comment">//    file.CopyTo(destinationFile, true);</span></span><br><span class="line"><span class="comment">//&#125;</span></span><br><span class="line">WebClient wc = <span class="keyword">new</span> WebClient(); <span class="comment">//创建网络通信实例</span></span><br><span class="line"><span class="keyword">byte</span>[] <span class="keyword">by</span> = <span class="keyword">new</span> <span class="keyword">byte</span>[<span class="number">1024</span>]; <span class="comment">//接收数据的数组</span></span><br><span class="line">WriteTextLog(<span class="string">"beforeCheck:"</span>,sourceFile.ToString()+<span class="string">"|"</span>+destinationFile, DateTime.Now);</span><br><span class="line">WriteTextLog(<span class="string">"check:"</span>, UrlCheck(sourceFile).ToString(), DateTime.Now);</span><br><span class="line"><span class="keyword">if</span> (UrlCheck(sourceFile)) <span class="comment">// 这里的Urlcheck是必须的</span></span><br><span class="line">&#123;</span><br><span class="line">    WriteTextLog(<span class="string">"savefile:"</span>, sourceFile.ToString() +<span class="string">"|"</span>+ destinationFile, DateTime.Now);</span><br><span class="line">    FileStream fs = <span class="keyword">new</span> FileStream(destinationFile, FileMode.Create, FileAccess.Write); <span class="comment">//创建文件</span></span><br><span class="line">    BinaryWriter bw = <span class="keyword">new</span> BinaryWriter(fs);</span><br><span class="line">    <span class="keyword">by</span> = wc.DownloadData(sourceFile);</span><br><span class="line">    bw.Write(<span class="keyword">by</span>, <span class="number">0</span>, <span class="keyword">by</span>.Length);</span><br><span class="line">    bw.Close();</span><br><span class="line">    fs.Close(); <span class="comment">//关闭数据流</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li><li><p>URL的Check需要判断上面的URL是否是网络地址</p> <figure class="highlight csharp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment">* 如果路径中含有http或者https,就进行webrequest的处理</span></span><br><span class="line"><span class="comment">**/</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">bool</span> <span class="title">UrlCheck</span>(<span class="params"><span class="keyword">string</span> strUrl</span>)</span></span><br><span class="line"><span class="function">    </span>&#123;</span><br><span class="line">        <span class="keyword">if</span> (!strUrl.Contains(<span class="string">"http://"</span>) &amp;&amp; !strUrl.Contains(<span class="string">"https://"</span>))</span><br><span class="line">        &#123;</span><br><span class="line">            strUrl = <span class="string">"http://"</span> + strUrl;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">try</span></span><br><span class="line">        &#123;</span><br><span class="line">            HttpWebRequest myRequest = (HttpWebRequest)WebRequest.Create(strUrl);</span><br><span class="line">            myRequest.Method = <span class="string">"HEAD"</span>;</span><br><span class="line">            myRequest.Timeout = <span class="number">20000</span>;  <span class="comment">//超时时间20秒</span></span><br><span class="line">            HttpWebResponse res = (HttpWebResponse)myRequest.GetResponse();</span><br><span class="line">            Boolean te;</span><br><span class="line">            <span class="keyword">if</span> (res.StatusCode == HttpStatusCode.OK) te = <span class="literal">true</span>;</span><br><span class="line">            <span class="keyword">else</span> te = <span class="literal">false</span>;</span><br><span class="line">            res.Close();</span><br><span class="line">            <span class="keyword">return</span> te;</span><br><span class="line">            </span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">catch</span></span><br><span class="line">        &#123;</span><br><span class="line">            <span class="keyword">return</span> <span class="literal">false</span>;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure></li><li><p>上面的日志文件会在项目目录下生成日志文件</p> <figure class="highlight csharp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">WriteTextLog</span>(<span class="params"><span class="keyword">string</span> action, <span class="keyword">string</span> strMessage, DateTime time</span>)</span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="keyword">string</span> path = AppDomain.CurrentDomain.BaseDirectory + <span class="string">@"System\Log\"</span>;</span><br><span class="line">    <span class="keyword">if</span> (!Directory.Exists(path))</span><br><span class="line">        Directory.CreateDirectory(path);</span><br><span class="line"></span><br><span class="line">    <span class="keyword">string</span> fileFullPath = path + time.ToString(<span class="string">"yyyy-MM-dd"</span>) + <span class="string">".System.txt"</span>;</span><br><span class="line">    StringBuilder str = <span class="keyword">new</span> StringBuilder();</span><br><span class="line">    str.Append(<span class="string">"Time:    "</span> + time.ToString() + <span class="string">"\r\n"</span>);</span><br><span class="line">    str.Append(<span class="string">"Action:  "</span> + action + <span class="string">"\r\n"</span>);</span><br><span class="line">    str.Append(<span class="string">"Message: "</span> + strMessage + <span class="string">"\r\n"</span>);</span><br><span class="line">    str.Append(<span class="string">"-----------------------------------------------------------\r\n\r\n"</span>);</span><br><span class="line">    StreamWriter sw;</span><br><span class="line">    <span class="keyword">if</span> (!File.Exists(fileFullPath))</span><br><span class="line">    &#123;</span><br><span class="line">        sw = File.CreateText(fileFullPath);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">else</span></span><br><span class="line">    &#123;</span><br><span class="line">        sw = File.AppendText(fileFullPath);</span><br><span class="line">    &#125;</span><br><span class="line">    sw.WriteLine(str.ToString());</span><br><span class="line">    sw.Close();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li></ol>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;开发考试院笔迹鉴别系统的过程中遇到了很多的问题，也学到了很多，将其记录下来。以供今后回顾。&lt;br&gt;&lt;strong&gt;Warning:&lt;/strong&gt;项目构建和项目打开的时候一定要使用解决方法，不要使用网站！一定要使用解决方法，不要使用网站！一定要使用解决方法，不要使用网站！
      
    
    </summary>
    
      <category term="开发笔记" scheme="https://stonema.github.io/categories/%E5%BC%80%E5%8F%91%E7%AC%94%E8%AE%B0/"/>
    
    
      <category term=".net技术" scheme="https://stonema.github.io/tags/net%E6%8A%80%E6%9C%AF/"/>
    
      <category term="web开发" scheme="https://stonema.github.io/tags/web%E5%BC%80%E5%8F%91/"/>
    
  </entry>
  
  <entry>
    <title>日记</title>
    <link href="https://stonema.github.io/2018/07/09/%E6%97%A5%E8%AE%B0/"/>
    <id>https://stonema.github.io/2018/07/09/日记/</id>
    <published>2018-07-09T10:00:09.000Z</published>
    <updated>2020-01-18T01:45:05.206Z</updated>
    
    <content type="html"><![CDATA[<p> 搞不明白这些研究生导师都是在干什么……<br> 为中国的教育堪忧！</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt; 搞不明白这些研究生导师都是在干什么……&lt;br&gt; 为中国的教育堪忧！&lt;/p&gt;

      
    
    </summary>
    
      <category term="生活" scheme="https://stonema.github.io/categories/%E7%94%9F%E6%B4%BB/"/>
    
    
      <category term="日记" scheme="https://stonema.github.io/tags/%E6%97%A5%E8%AE%B0/"/>
    
  </entry>
  
  <entry>
    <title>OpenCV图像处理总结</title>
    <link href="https://stonema.github.io/2018/07/05/OpenCV%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86%E6%80%BB%E7%BB%93/"/>
    <id>https://stonema.github.io/2018/07/05/OpenCV图像处理总结/</id>
    <published>2018-07-05T02:35:19.000Z</published>
    <updated>2020-01-18T01:45:05.171Z</updated>
    
    <content type="html"><![CDATA[<p>OpenCV是一个基于BSD许可（开源）发行的跨平台计算机视觉库，可以运行在Linux、Windows、Android和Mac OS操作系统上。它轻量级而且高效——由一系列 C 函数和少量 C++ 类构成，同时提供了Python、Ruby、MATLAB等语言的接口，实现了图像处理和计算机视觉方面的很多通用算法。OpenCV用C++语言编写，主要用于图像处理。</p><p>基本方法包括但不限于：</p><ul><li>图像灰度化</li><li>图像二值化</li><li>图像降噪，增强</li><li>图像特征提取</li><li>全局特征与局部特征</li></ul><h1 id="一些图像方面的基本知识："><a href="#一些图像方面的基本知识：" class="headerlink" title="一些图像方面的基本知识："></a>一些图像方面的基本知识：</h1><h2 id="图像增强（image-enhancement）"><a href="#图像增强（image-enhancement）" class="headerlink" title="图像增强（image enhancement）"></a>图像增强（image enhancement）</h2><p>图像增强可以分为两大类: 频率域和空间域（频域和空域）。</p><ul><li>前者把图像看成一种二维信号，对其进行基于二维傅里叶变换的信号增强。采用低通滤波（即只让低频信号通过）法，可去掉图中的噪声；采用高通滤波法，则可增强边缘等高频信号，使模糊的图片变得清晰。</li><li>后者空间域法中具有代表性的算法有局部求平均值法和中值滤波（取局部邻域中的中间像素值）法等，它们可用于去除或减弱噪声。</li></ul><h2 id="灰度化"><a href="#灰度化" class="headerlink" title="灰度化"></a>灰度化</h2><p>什么是灰度化？从字面意思来看就是将彩色图片变成灰色的。1：那么如何实现的呢？2：以及为什么要这样做呢？<br>首先我们知道常见的图像都是彩色图像，色彩的展示靠的是计算机计算出每个像素点的色值，比如一个像素位上的颜色是黄色，那么对于RGB三通道的图像来讲，就是R通道，G通道，B通道各有一个色值，然后将三者通过计算之后叠加，得到这个黄色的色值。当然我们上述说的都是RGB空间中的颜色处理，对于计算机上显示的彩色图像还有很多的颜色空间，比如HSV，和HLS等等。彩色图像中的每个像素的颜色有R、G、B三个分量决定，每个分量占一个字节，也就是8个bit，所以每个分量有$2^{8}=255$个颜色等级可以表示。所以一个24深度的RGB图像，每个像素点就有1600多万中色彩可以表示。如果我们想将其处理成灰色呢？</p><h3 id="第一个问题，如何实现"><a href="#第一个问题，如何实现" class="headerlink" title="第一个问题，如何实现?"></a><strong>第一个问题，如何实现?</strong></h3><p>在RGB模型中，如果R=G=B时，则彩色表示一种灰度颜色，其中R=G=B的值叫灰度值，因此，灰度图像每个像素只需一个字节存放灰度值（又称强度值、亮度值），灰度范围为0-255。也就是说这时候图像的RGB三个通道的值都是相同的。对于图像的灰度化，有如下几种处理方法：</p><ul><li>分量法<br>将彩色图像中的三分量的亮度作为三个灰度图像的灰度值，可根据应用需要选取一种灰度图像。<script type="math/tex; mode=display">f_{1}(i,j)=R(i,j) \\f_{2}(i,j)=G(i,j) \\f_{3}(i,j)=B(i,j) \\</script>其中$f_{k}(i,j)(k=1,2,3)$为转换后的灰度图像在图像坐标为(i,j)处的灰度值。</li><li>最大值法<br>将彩色图像中的三分量亮度的最大值作为灰度图的灰度值。<script type="math/tex; mode=display">f(i,j)=max(R(i,j),G(i,j),B(i,j))</script></li><li>平均值法<br>将彩色图像中的三分量亮度求平均得到一个灰度值。<script type="math/tex; mode=display">f(i,j)=(R(i,j)+G(i,j)+B(i,j)) /3</script></li><li>加权平均法<br>根据重要性及其它指标，将三个分量以不同的权值进行加权平均。由于人眼对绿色的敏感最高，对蓝色敏感最低，因此，按下式对RGB三分量进行加权平均能得到较合理的灰度图像。<script type="math/tex; mode=display">f(i,j)=0.30R(i,j)+0.59G(i,j)+0.11B(i,j))</script></li><li>Opencv中图像灰度化处理：<br>在Opencv中可以通过以上几种方法的数值计算来得到灰度图像也可以通过opencv提供的颜色空间转换函数来得到。<br>Opencv封装灰度法：<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//彩色图转为灰度图方法调用</span></span><br><span class="line">cv::cvtColor(rgbMat, greyMat, CV_BGR2GRAY);</span><br></pre></td></tr></table></figure></li></ul><h3 id="第二个问题，为什么要这样灰度化"><a href="#第二个问题，为什么要这样灰度化" class="headerlink" title="第二个问题，为什么要这样灰度化?"></a><strong>第二个问题，为什么要这样灰度化?</strong></h3><p>灰度图像不会消除图像的边缘信息，纹理信息，梯度信息等，所以使用灰度化后的图片可以完美保留这些有用的信息，同时还能节省图片的存储空间，（因为RGB压缩为一个通道来表示）所以这样的优的显而易见。<br>还有就是梯度信息对于识别物体来说很重要，所以我们可以把灰度图像看作图像的强度(Intensity)，来求一些梯度特征，比较常用的有 HOG，LBP，SIFT等等。</p><h2 id="像素点之间的关系"><a href="#像素点之间的关系" class="headerlink" title="像素点之间的关系"></a>像素点之间的关系</h2><p><img src="/2018/07/05/OpenCV图像处理总结/opencv1.png" alt="opencv"><br><img src="/2018/07/05/OpenCV图像处理总结/opencv2.png" alt="opencv"></p><h2 id="像素梯度"><a href="#像素梯度" class="headerlink" title="像素梯度"></a>像素梯度</h2><p>图像梯度可以把图像看成二维离散函数，图像梯度其实就是这个二维离散函数的求导：<br>图像梯度: </p><script type="math/tex; mode=display">G(x,y) = dx(i,j)+dy(i,j) \\dx(i,j) = I(i+1,j) - I(i,j) \\dy(i,j) = I(i,j+1) - I(i,j) \\</script><p>其中，I是图像像素的值(如：RGB值)，(i,j)为像素的坐标。图像梯度一般也可以用中值差分：</p><script type="math/tex; mode=display">dx(i,j) = \frac{I(i+1,j)-I(i-1,j)}{2}; \\dy(i,j) = \frac{I(i,j+1)-I(i,j-1)}{2};</script><p>图像边缘一般都是通过对图像进行梯度运算来实现的。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;OpenCV是一个基于BSD许可（开源）发行的跨平台计算机视觉库，可以运行在Linux、Windows、Android和Mac OS操作系统上。它轻量级而且高效——由一系列 C 函数和少量 C++ 类构成，同时提供了Python、Ruby、MATLAB等语言的接口，实现了图
      
    
    </summary>
    
      <category term="图形学" scheme="https://stonema.github.io/categories/%E5%9B%BE%E5%BD%A2%E5%AD%A6/"/>
    
    
      <category term="特征提取" scheme="https://stonema.github.io/tags/%E7%89%B9%E5%BE%81%E6%8F%90%E5%8F%96/"/>
    
      <category term="OpenCV" scheme="https://stonema.github.io/tags/OpenCV/"/>
    
      <category term="灰度化" scheme="https://stonema.github.io/tags/%E7%81%B0%E5%BA%A6%E5%8C%96/"/>
    
      <category term="全局特征" scheme="https://stonema.github.io/tags/%E5%85%A8%E5%B1%80%E7%89%B9%E5%BE%81/"/>
    
      <category term="局部特征" scheme="https://stonema.github.io/tags/%E5%B1%80%E9%83%A8%E7%89%B9%E5%BE%81/"/>
    
  </entry>
  
  <entry>
    <title>BP神经网络</title>
    <link href="https://stonema.github.io/2018/06/06/BP%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/"/>
    <id>https://stonema.github.io/2018/06/06/BP神经网络/</id>
    <published>2018-06-06T02:07:22.000Z</published>
    <updated>2020-01-18T01:45:05.152Z</updated>
    
    <content type="html"><![CDATA[<p>感谢师姐，感谢博主：Charlotte77，感谢魏老师，感谢龙哥等等同学与前辈在学习的道路上为我指点迷津。</p><p><strong>反向传播算法(Back Propagation)分二步进行，即正向传播和反向传播。这两个过程简述如下：</strong></p><ol><li>正向传播<br>输入的样本从输入层经过隐单元一层一层进行处理，传向输出层；在逐层处理的过程中。在输出层把当前输出和期望输出进行比较，如果现行输出不等于期望输出，则进入反向传播过程。</li><li>反向传播<br>反向传播时，把误差信号按原来正向传播的通路反向传回，逐层修改连接权值，以使得代价函数趋向最小。</li></ol><hr><h1 id="详细过程介绍："><a href="#详细过程介绍：" class="headerlink" title="详细过程介绍："></a>详细过程介绍：</h1><p>首先要明白<strong>BP神经网络是神经网络的权值更新过程运用了BP算法</strong>而得名的。<br>神经网络结构有输入层，隐藏层（可能包含多层），输出层组成；在神经网络中每一个节点的都与上一层的所有节点相连，称为全连接。神经网络的上一层输出的数据是下一层的输入数据。<br><img src="/2018/06/06/BP神经网络/BP1.png" alt="pb网络"><br>在图中的神经网络中，原始的输入数据，通过第一层隐含层的计算得出的输出数据，会传到第二层隐含层。而第二层的输出，又会作为输出层的输入数据。<br>需要注意的是，图中的没个节点都可以分为两个部分：比如 $f<em>{1}(e)$ 它的前半部分可以表示的是，$x</em>{1}$ 和 $x_{2}$共同作用后的结果，然后它的后半部分这个结果经过激活函数的映射后得到的值。</p><h1 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h1><p><a href="http://www.cnblogs.com/charlotte77/p/5629865.html" target="_blank" rel="noopener">http://www.cnblogs.com/charlotte77/p/5629865.html</a></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;感谢师姐，感谢博主：Charlotte77，感谢魏老师，感谢龙哥等等同学与前辈在学习的道路上为我指点迷津。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;反向传播算法(Back Propagation)分二步进行，即正向传播和反向传播。这两个过程简述如下：&lt;/strong&gt;&lt;/p&gt;
&lt;ol
      
    
    </summary>
    
      <category term="神经网络" scheme="https://stonema.github.io/categories/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/"/>
    
    
      <category term="神经网络" scheme="https://stonema.github.io/tags/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/"/>
    
      <category term="BP算法" scheme="https://stonema.github.io/tags/BP%E7%AE%97%E6%B3%95/"/>
    
  </entry>
  
  <entry>
    <title>认识卷积神经网络CNN</title>
    <link href="https://stonema.github.io/2018/06/04/%E8%AE%A4%E8%AF%86%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/"/>
    <id>https://stonema.github.io/2018/06/04/认识卷积神经网络/</id>
    <published>2018-06-04T06:53:29.000Z</published>
    <updated>2020-01-18T01:45:05.211Z</updated>
    
    <content type="html"><![CDATA[<h1 id="卷积神经网络"><a href="#卷积神经网络" class="headerlink" title="卷积神经网络"></a>卷积神经网络</h1><p><strong>卷积神经网络，是一种前馈神经网络，人工神经元可以响应周围单元，可以进行大型图像处理。卷积神经网络包括卷积层和池化层。</strong></p><p>首先来看上一篇文章中的图，这个图就是用来描述CNN<br><img src="/2018/06/04/认识卷积神经网络/cnn0.png" alt="cnn"></p><h2 id="从入坑开始-——-CNN"><a href="#从入坑开始-——-CNN" class="headerlink" title="从入坑开始 —— CNN"></a>从入坑开始 —— CNN</h2><p>或许这并不是你接触到的第一个深度学习领域、或者是机器学习领域的专业名词，但是搞明白它，足以让我们学习到很多知识以供后续的学习和进步。<br>CNN（Convolutional Neural Networks）也就是我们常说的卷积神经网络，单单从这个名词来看，这里就有几个概念需要我们来弄明白——什么是<strong>卷积</strong>，什么是<strong>神经网络</strong>。</p><h2 id="卷积"><a href="#卷积" class="headerlink" title="卷积"></a>卷积</h2><p>最早接触这个词的时候是读大学的时候学习《数字信号处理》这门课程，里面在FFT快速傅里叶变化的时候有讲到卷积运算，$\bigotimes$ 表示卷积运算，那么：</p><script type="math/tex; mode=display">f(x) \bigotimes g(x) = \int_{-\infty}^{+\infty} f(\tau)g(x-\tau)d\tau\tag{$1$}</script><p>离散化的卷积运算：</p><script type="math/tex; mode=display">y(n) = \sum_{i=-\infty}^{+\infty}x(i)h(n-i)=x(n)*h(n)\tag{$2$}</script><p>但是！！！这里神经网络中的卷积运算，并非傅里叶变换中的卷积运算，这里的卷积运算是以图像和卷积核（也叫滤波器）对应位置相乘再相加得到的结果：如下图所示：<br><img src="/2018/06/04/认识卷积神经网络/CNN.gif" alt="cnn"><br>图中的黄色区域的标注数字为卷积核，如下所示：</p><script type="math/tex; mode=display"> \left[ \begin{matrix}   1 & 0 & 1 \\   0 & 1 & 0 \\   1 & 0 & 1  \end{matrix}  \right]\tag{$3$}</script><p>我们可以看到，右边得到的结果是左边大矩阵和小矩阵卷积得到的，大矩阵就是我们的原图像，里面的值就是图像像素的值，而小矩阵就是卷积核。两者对应位置相乘然后依次相加，得到新矩阵的一个位置的值，然后向右滑动卷积核（滑动的间隔可调）得到新的位置的值。这就是神经网络中的<strong>卷积</strong>。这里要注意的是，我们从上图中可以看到，卷积核在移动的过程中是一个一个像素滑动的，这个滑动的间隔叫做<strong>步长</strong>（strides），strides的值可以自己设置，表示滑动的间隔的大小。通过这样的操作，我们可以直观的看到，原图像尺寸被卷积操作<strong>缩小</strong>了。这就是卷积操作的作用，可以通过卷积核把一个小区间内的<strong>特征</strong>提取出来，并以数值化的形式表现出来。如果你要深挖为什么要用这样的计算形式来处理卷积核与图形，建议看图像滤波方面的内容。</p><p>那么到这里，我们初步具备了学习卷积神经网络的基础知识。Next，我们开始了解卷积神经网络中的各层，以及它们的工作内容。</p><h2 id="卷积神经网络中的分层"><a href="#卷积神经网络中的分层" class="headerlink" title="卷积神经网络中的分层"></a>卷积神经网络中的分层</h2><p>卷积神经网络，是一种前馈神经网络，卷积神经网络包括卷积层和池化层。</p><h2 id="输入层（Input-Layer）"><a href="#输入层（Input-Layer）" class="headerlink" title="输入层（Input Layer）"></a>输入层（Input Layer）</h2><p>输入层：<br>该层要做的处理主要是对原始图像数据进行预处理，其中包括：</p><ul><li>去均值：<br>把输入数据各个维度都中心化为0，如下图所示，其目的就是把样本的中心拉回到坐标系原点上。</li><li>归一化：<br>幅度归一化到同样的范围，如下所示，即减少各维度数据取值范围的差异而带来的干扰，比如，我们有两个维度的特征A和B，A范围是0到10，而B范围是0到10000，如果直接使用这两个特征是有问题的，好的做法就是归一化，即A和B的数据都变为0到1的范围。</li><li>PCA/白化：<br>用PCA降维；白化是对数据各个特征轴上的幅度归一化</li></ul><h2 id="卷积层（Convention-Layer）"><a href="#卷积层（Convention-Layer）" class="headerlink" title="卷积层（Convention Layer）"></a>卷积层（Convention Layer）</h2><p>卷积神经网络(CNN)第一次提出是在1997年，杨乐春（LeNet）大神的一篇关于数字OCR识别的论文，在2012年的ImageNet竞赛中CNN网络成功击败其它非DNN模型算法，从此获得学术界的关注与工业界的兴趣。从本质上来说，图像卷积都是离散卷积，离散卷积本质上是线性变换、(这也是为什么要引入激活函数)上面已经介绍了离散卷积运算的形式，卷积层也是卷积神经网络中最重要的一个层：<br>卷积在上文，以及之前的文章中我们介绍过它的运算方式，实际卷积的过程或者说卷积运算的过程，就是在提取原矩阵中的特征，（或者理解为对原矩阵做滤波）所以每次卷积操作完成后，得到的都是一个featuremap<br>下面的图片详细解释了卷积的过程：<br><img src="/2018/06/04/认识卷积神经网络/cnnprocess.gif" alt="cnnprocess"><br>上面这个图中有几个重要的名词，我们需要了解：</p><ul><li>深度/depth（就是每次卷积能得到多少个featuremap）</li><li>步长/stride （窗口一次滑动的长度）</li><li>填充值/zero-padding（边缘填充0）VALID（边缘不填充）<br>上面就是单层卷积操作的全部过程了，对于多层卷积我们以一个例子来说明：<br><img src="/2018/06/04/认识卷积神经网络/rgbcnn.png" alt="多层卷积"><br>比如上图中输入为5x5x2,卷积核为3个3x3的filter，填充方式为VALID，那么这幅图从下往上看，我们第一步分别用三个卷积核对原图像做卷积得到第二层的3个3x3x2的结果，然后对于每一个3x3x2的结果，两层featuremap的对应位置相加，就得到一张3x3的featuremap，同样其他卷积核得到的结果相同，这样就一共得到了三张featuremap，所以说最后输出的featuremap数量与卷积核的数量相同。</li></ul><h2 id="池化层（Sampling-Layer，Pooling-Layer）"><a href="#池化层（Sampling-Layer，Pooling-Layer）" class="headerlink" title="池化层（Sampling Layer，Pooling Layer）"></a>池化层（Sampling Layer，Pooling Layer）</h2><p>不知道为什么使用‘池化’这个词，实际这个过程更符合“采样”,我的猜测是“采样”更多的体现的是从已有样本中选择出代表，而池化是使用某些运算后的结果作为代表，并不一定是在原样本中采样。<br><img src="/2018/06/04/认识卷积神经网络/pooling.gif" alt="pooling"><br>在CNN网络中卷积池之后会跟上一个池化层，池化层的作用是提取局部均值与最大值，根据计算出来的值不一样就分为均值池化层与最大值池化层，一般常见的多为最大值池化层。池化的时候同样需要提供filter的大小、步长。</p><h2 id="全连接（Full-Connection-Layer）"><a href="#全连接（Full-Connection-Layer）" class="headerlink" title="全连接（Full-Connection Layer）"></a>全连接（Full-Connection Layer）</h2><p><img src="/2018/06/04/认识卷积神经网络/fullconnection.png" alt="fullconnection"><br>上图的最后两层小圆圈就是全连接层，全连接层的作用就是将前面的二维数据输出成一维数据！<br>啊~终于快结束了~学到这里脑子已经感觉有些木了。别急马上结束~<br>看到上面这个图，我的第一反应是，它是如何把20x12x12变成100x1x1的？这里我们套用网上的一个例子:<br><img src="/2018/06/04/认识卷积神经网络/full0.jpg" alt="full"><br><img src="/2018/06/04/认识卷积神经网络/full1.jpg" alt="full1"><br>这个过程可以理解为在中间做了一个卷积,但是这里的卷积核与前面的输出层图像维度相同，都是5层，每层的滤波器都是相同的，但是我们有4096个卷积核。<br><img src="/2018/06/04/认识卷积神经网络/full2.jpg" alt="full2"><br>从上图我们可以看出，我们用一个3x3x5的filter 去卷积激活函数的输出,得到的结果就是一个fully connected layer 的一个神经元的输出，这个输出就是一个值<br>因为我们有4096个神经元<br>我们实际就是用一个3x3x5x4096的卷积层去卷积激活函数的输出。<br>“这一步卷积一个非常重要的作用就是把分布式特征representation映射到样本标记空间”—知乎：蒋竺波<br>例子：<br><img src="/2018/06/04/认识卷积神经网络/mao.jpg" alt="mao"><br>目标是检查图片中有没有猫，而不关心猫的位置。</p><p>到这里我们明白了一点：卷积层就是在提取特征，全连接层就是在分类,全连接层中的没个数值就是判断前面的卷积层有没有提取到目标的某个特征的依据。比如全连接层输出为[1,0,1,1];则表示，除了第二个特征，其余的特征都检测到了。<br><img src="/2018/06/04/认识卷积神经网络/full3.jpg" alt="full3"><br>红色的神经元表示特征被找到。(激活了)<br>最终的输出形式：<br><img src="/2018/06/04/认识卷积神经网络/full4.jpg" alt="full4"><br>那么全连接层对模型影响参数就是三个：</p><p>全接解层的总层数（长度）<br>单个全连接层的神经元数（宽度）<br>激活函数</p><h2 id="输出层（Output-Layer）"><a href="#输出层（Output-Layer）" class="headerlink" title="输出层（Output Layer）"></a>输出层（Output Layer）</h2><p>……</p><hr><p>有了上面对卷积神经网络的了解，我们要继续了解一下其他内容，下面的前馈网络和BP网络都是对网络中权值更新的算法。</p><h2 id="前馈神经网络"><a href="#前馈神经网络" class="headerlink" title="前馈神经网络"></a>前馈神经网络</h2><p>现在讲的都是前馈网络，后来人们发现权值更新使用了BP思想以后，才有了BP神经网络这个名词。</p><h2 id="BP神经网络"><a href="#BP神经网络" class="headerlink" title="BP神经网络"></a>BP神经网络</h2><p>首先不要认为BP网络与卷积网络是并列关系，两者专注的领域不同，BP网络的目的是使用反向传递的思想来更新权值，而卷积网络的目的是降低网络中神经元的连接数量从而减少权值的计算。</p><h1 id="其他卷积神经网络"><a href="#其他卷积神经网络" class="headerlink" title="其他卷积神经网络"></a>其他卷积神经网络</h1><ul><li>LeNet，这是最早用于数字识别的CNN</li><li>AlexNet， 2012 ILSVRC比赛远超第2名的CNN，比</li><li>LeNet更深，用多层小卷积层叠加替换单大卷积层。</li><li>ZF Net， 2013 ILSVRC比赛冠军</li><li>GoogLeNet， 2014 ILSVRC比赛冠军</li><li>VGGNet， 2014 ILSVRC比赛中的模型，图像识别略差于GoogLeNet，但是在很多图像转化学习问题(比如object detection)上效果奇好</li></ul><h1 id="深度学习"><a href="#深度学习" class="headerlink" title="深度学习"></a>深度学习</h1><h1 id="卷积神经网络的常用框架"><a href="#卷积神经网络的常用框架" class="headerlink" title="卷积神经网络的常用框架"></a>卷积神经网络的常用框架</h1><ul><li>Caffe<ul><li>源于Berkeley的主流CV工具包，支持C++,python,matlab</li><li>Model Zoo中有大量预训练好的模型供使用</li></ul></li><li>Torch<ul><li>Facebook用的卷积神经网络工具包</li><li>通过时域卷积的本地接口，使用非常直观</li><li>定义新网络层简单</li></ul></li><li>TensorFlow<ul><li>Google的深度学习框架</li><li>TensorBoard可视化很方便</li><li>数据和模型并行化好，速度快</li></ul></li></ul><h1 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h1><p><a href="https://www.jianshu.com/p/fe428f0b32c1" target="_blank" rel="noopener">卷积神经网络</a><br><a href="https://www.zhihu.com/question/41037974" target="_blank" rel="noopener">全连接层的含义</a></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;卷积神经网络&quot;&gt;&lt;a href=&quot;#卷积神经网络&quot; class=&quot;headerlink&quot; title=&quot;卷积神经网络&quot;&gt;&lt;/a&gt;卷积神经网络&lt;/h1&gt;&lt;p&gt;&lt;strong&gt;卷积神经网络，是一种前馈神经网络，人工神经元可以响应周围单元，可以进行大型图像处理。卷积神经
      
    
    </summary>
    
      <category term="神经网络" scheme="https://stonema.github.io/categories/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/"/>
    
    
      <category term="机器学习" scheme="https://stonema.github.io/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
      <category term="感知器" scheme="https://stonema.github.io/tags/%E6%84%9F%E7%9F%A5%E5%99%A8/"/>
    
      <category term="卷积神经网络" scheme="https://stonema.github.io/tags/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/"/>
    
  </entry>
  
  <entry>
    <title>认识人工神经网络</title>
    <link href="https://stonema.github.io/2018/05/29/%E4%BB%8EANN%E5%88%B0CNN/"/>
    <id>https://stonema.github.io/2018/05/29/从ANN到CNN/</id>
    <published>2018-05-29T05:09:53.000Z</published>
    <updated>2020-01-18T01:45:05.188Z</updated>
    
    <content type="html"><![CDATA[<p><strong>写在前面：</strong> 或许机器学习这部分内容不应该就这么展开，应该循序渐进，待自己有了深层次了解以后，从基本的回归、分类讲起，但是最后还是选择了边学习边总结的形式，至少能详细记录自己曾经踩过的坑，记录自己的学习路线，也算是个好的形式吧！</p><hr><p>周末跟北京的兄弟们聚了一波，每次见他们的感觉都特别的不一样，每次见完面后都感觉自己受了很大鼓舞，有无限动力。W哥好像一直都是这么的有激情有干劲儿，YL好像一直这么的能钻研从来不觉得累，而且他们的努力程度远在我认识的其他人之上！一起加油~</p><hr><h1 id="引言"><a href="#引言" class="headerlink" title="引言"></a>引言</h1><p>我相信很多人跟我一样，接触深度学习的最初原因是它很火听起来很厉害，而对于具体是如何实现的，自己根本闹不清……看一些论文、博客的时候都是看到一些类似下图的这样的图片，然后告诉自己：嗯~我大概了解深度学习的概念了。今天我们正儿八经的把它的皮扒开，认真分析它的经脉连通，深入了解什么是神经网络！什么是卷积神经网络，什么是BP神经网络，又是如何延伸到深度学习的！<br><img src="/2018/05/29/从ANN到CNN/cnn0.png" alt="cnn"></p><p>本文我们从神经元讲解到感知器，再到神经网络，带你认识最基本的神经元，然后了解感知器，神经网络是如何工作的！为了保证我的思路不混乱，保证讲解的路线的正确性，我先以自己踩过的坑为带入点，然后依次深入。有关CNN，BP网络，等等我们会在后续文章陆续更新，希望通过几篇文章，理清自己的思路，所机器学习领域的概念有个统筹的认识。</p><h1 id="神经网络"><a href="#神经网络" class="headerlink" title="神经网络"></a>神经网络</h1><p>好~我们初步解决了一个小问题，那么已经开始上道了，继续分析表象——<strong>神经网络</strong>，这个词~听起来真的高大上有木有！！第一次听到的时候也是上大学的时候，那时候先进一点的同学都在写神经网络算法，学什么蚁群算法，支持向量机，balabala~~一大堆在当时根本听不懂的名词~那，人总是要进步的，当时不愿意学，研究生再不学就有点耍流氓了~这里我们先介绍什么是<strong>神经网络</strong>。</p><h2 id="神经元"><a href="#神经元" class="headerlink" title="神经元"></a>神经元</h2><p>如果你和我一样，是想从0开始，把所有概念全弄懂搭建自己的知识脉络，而不仅仅是关心应用层的东西，我希望你可以看看这部分，看看我这个愚钝的人是如何坑自己的，如果你早已对这些基本概念了解的熟烂于心，建议跳过。<br><strong>神经元</strong>，这个词乍听起来怎么都不能和计算机专业联系在一起，它怎么也得是个生物学相关的东西啊！没错，神经元本就是生物学的概念，第一个人造神经元是1943年由Warren McCulloch和Walter Pitts首次提出的，最早用来作为大脑中“神经网络”的计算模型。如果你不清楚神经元的工作原理，请看下面这个图，神经元有很多个输入端，当输入的信号经过神经元的细胞核处理超过某个阈值后，就把生成的信号向下传递。<br><img src="/2018/05/29/从ANN到CNN/Neuron.png" alt="神经元"><br>那么知道了真正的神经元的样子，人工神经元实际上就是模拟的生物学中的神经元，如下图所示，左侧的就是输入，中间圆圈就是处理单元，后面的就是输出：<br><img src="/2018/05/29/从ANN到CNN/SingleNeuron.png" alt="人工神经元"><br>看到这个图，总的来讲我们要有一个概念，这个东西基本表示的是：有多个输入单元，然后将这些输入单元经过某种运算以后得到一个输出。<br>上图这个神经元的输入值是$x<em>{1},x</em>{2},x<em>{3}$以及截距b这里是$+1$,中间是运算单元，输出是$h</em>{W,b}(x)=f(W^{T}x)=f(\sum^{3}<em>{i=1}W</em>{i}x_{i}+b)$ ,其中函数 $f:\Re \longmapsto \Re$ 被称<strong>激活函数</strong>。</p><p>到这里，其实对于一个非数学或者计算机专业的同学来说已经有点懵了……（其实即使是数学和计算机专业的我，一开始也是懵的……）那么这里这个函数有什么作用呢？我们用一个例子来说明：比如我们有个数据a它的形式是这样的 {$x^{0},1$}，现在我们想通过一个函数能够使得$f(x^{0})=1$那么这个函数$f(x)$就是我们要研究的对象，也就是我们的模型！只不过这里是最简单的一维数据模型，那么让我们把原始输入复杂一点，假设输入是多维数据，（可以用向量来表示）那么就成了$(\boldsymbol x^{(0)},1)$ 也就是说对于这个输入进来的向量，我需要给每个维度的数据配比不同的权重来使得$f(\boldsymbol x^{(0)}) = 1,$;到这里依然很好理解，但是这里还是在讲单一数据，那么对于数据集呢？假设我们有这样的数据集$((\boldsymbol x^{i}),\boldsymbol y^{(i)})$,那我们就无法使用一个神经元来解决问题了，一个不行的话，就多个！那么多个神经元也就组成了我们的神经网络，（多层感知器）。</p><h2 id="感知器（Perceptron）"><a href="#感知器（Perceptron）" class="headerlink" title="感知器（Perceptron）"></a>感知器（Perceptron）</h2><p>多个神经元构成的组合结构可以成为感知机（感知器）。感知器分为单层感知器和多层感知器。感知器之所以叫感知器原因就是它具备某种感知功能，当我们的网络中具有众多感知各种事物的感知器的时候，也就构成了复杂的神经网络。具有了多重感知能力。<strong>这也是感知器与神经网络的关系</strong>。</p><p><strong>单层感知器</strong><br><img src="/2018/05/29/从ANN到CNN/Perceptron.png" alt="Perceptron"><br><strong>多层感知器</strong><br><img src="/2018/05/29/从ANN到CNN/multiPerceptron.png" alt="multiPerceptron"></p><h2 id="感知器的学习策略"><a href="#感知器的学习策略" class="headerlink" title="感知器的学习策略"></a>感知器的学习策略</h2><p><strong>我们需要介绍一下的是，感知机的学习策略，也是我们神经网络中的重点。</strong><br>首先要明白我们为什么要引入这样一个概念。通过了解上面的神经元和感知器得知，他们的目的是通过一个模型（多层感知器），能够使得样本集$((\boldsymbol x^{i}),\boldsymbol y^{(i)})$ 实现我们的输入$\boldsymbol x^{i}$ 都能和应有的输出$\boldsymbol y^{(i)}$对应上。所以我们的主要目的就是要得到这样的一个模型，对于上面的神经元来说，就是要得到针对各项输入的权重。能够完美匹配我们所有的输入。<br>好的~到这里，<strong>我们基本明确了我们的目标</strong>。让我们继续去了解如何解决这个问题<br>通常我们肯定会遇到这样的情况：我们给一组权重$(w^{i})$和函数$f(x)$它可能只能满足某些输入信号从$x^{(i)}$到$y^{(i)}$的映射，并不能适配所以的样本集。那么如何根据已经正确适配或是适配错误的输出来调整我们的$w^{(i)}$呢？这就引入了我们要讲的重点：<strong>学习策略</strong><br>感知器的学习规则是这样的：学习信号等于神经元期望输出的值与实际的输出值的差。</p><script type="math/tex; mode=display">Result = desired_{j} - output_{j} \tag{$1$}</script><p>$desired<em>{j}$表示期望望的输出，$output</em>{j}$表示实际的输出。$Result$就是误差，然后根据学习信号，就可以对权值进行更新，也就是我们所说的 <strong>学习</strong> 了。<br>看到这里不要慌，不要一见到公式就害怕，这里还是很好理解的。只不过把我们前面语言叙述的内容符号化了。<br>继续，看上面感知器中的图，$W$代表特征向量或者是特征矩阵，$\boldsymbol x$ 表示输入信号（样本集中的样本）。那么我们把上面的公式重新书写一下：</p><script type="math/tex; mode=display">output_{j} = f(W^{T}_{j} \cdot X) = sgn(W^{T}_{j} \cdot X) = \begin{cases}1,& W^{T}_{j}X\geqslant0\\-1,& W^{T}_{j}X<0\\\end{cases} \tag{$2$}</script><p>权值的调整：</p><script type="math/tex; mode=display">\vartriangle W_{j} = \eta[desired_{j}-sgn(W^{T}_{j}X)]X \tag{$3$}</script><p>这个公式右侧的 $\eta$ 表示学习率。权值的调整值 = 学习率$\times$误差$\times$输入信号。当实际的输出与我们期望的输出一致时，也就是$output = desired$ 权值就不需要再调整了。如果以我们的上述中的（5） 式为例，也就是实际的输出值是 1 或者 -1，所以结果可以简化为：</p><script type="math/tex; mode=display">\vartriangle W_{j} = \pm 2\eta X \tag{$4$}</script><p>这就是感知器的学习规则。至于学习率 $\eta$ 它的初始化要符合如下规律：</p><ul><li>学习率大于零，小于等于１</li><li>学习率太大，容易造成权值调整不稳定。</li><li>学习率太小，权值调整太慢，迭代次数太多。<br>最初感知器的规则很简单，可以总结为两步：</li></ul><ol><li>将权值初始化为0或者较小的随机数。</li><li>对每个训练样本：<ul><li>计算输出值；</li><li>更新权值；</li></ul></li></ol><p>输出值就是根据我们早先定义的 <strong>激活函数</strong> 或者 <strong>阶跃函数</strong> 预测的类标签$(output = g(z))$,（关于激活函数，我们下面会讲到）并且权值的更新可以写成：</p><script type="math/tex; mode=display">w_{j} = w_{j} + \vartriangle w_{j} \tag{$5$}</script><p>对于每个权值的增量，权值的更新值可以由如下学习规则得到：</p><script type="math/tex; mode=display">\vartriangle w_{j} = \eta (target^{(i)} - output^{(i)})x^{(i)}_{j} \tag{6}</script><p>其中 $\eta$ 表示学习速率（0.0和1.0之间的常数），“target”表示真实标签，“output”表示预测标签。需要注意的是，权值向量内的所有权值同步更新。具体来说，对于一个2维数据集，以如下方式描述更新：</p><script type="math/tex; mode=display">\vartriangle w_{0} = \eta (target^{(i)} - output^{(i)}) \tag{7}</script><script type="math/tex; mode=display">\vartriangle w_{1} = \eta (target^{(i)} - output^{(i)})x^{(i)}_{1} \tag{8}</script><script type="math/tex; mode=display">\vartriangle w_{2} = \eta (target^{(i)} - output^{(i)})x^{(i)}_{2} \tag{9}</script><p>设想一下，这种学习规则，如果感知器正确分类，则权值保持不变：</p><script type="math/tex; mode=display">\vartriangle w_{(j)} = \eta (-1^{(i)} -- 1^{(i)})x^{(i)}_{j} = 0 \tag{10}</script><script type="math/tex; mode=display">\vartriangle w_{(j)} = \eta (1^{(i)} - 1^{(i)})x^{(i)}_{j} = 0 \tag{11}</script><p>但是。如果感知器分类错误，那么权值会向正确“方向”调整：</p><script type="math/tex; mode=display">\vartriangle w_{(j)} = \eta (-1^{(i)} - 1^{(i)})x^{(i)}_{j} = \eta (-2)x^{(i)}_{j} \tag{12}</script><script type="math/tex; mode=display">\vartriangle w_{(j)} = \eta (1^{(i)} + 1^{(i)})x^{(i)}_{j} = \eta (2)x^{(i)}_{j} \tag{13}</script><p>这就是权值更新的详细过程，需要注意的是，<strong>感知器或者神经元分类针对的都是线性可分数据，这样才能保证感知器是收敛的。</strong>（关于线性不可分数据，下面会详细介绍）</p><h2 id="人工神经网络-ANN"><a href="#人工神经网络-ANN" class="headerlink" title="人工神经网络(ANN)"></a>人工神经网络(ANN)</h2><p>首先让我们了解一下神经网络的发展史：<br>1943年，神经科学家和控制论专家Warren McCulloch和逻辑学家Walter Pitts基于数学和阈值逻辑算法创造了一种神经网络计算模型；<br>1957年，心理学家Frank Rosenblatt创造了模式识别算法感知机，用简单的加减算法实现了两层的计算机学习网络；<br>1974年，Paul Werbos在博士论文中提出了用误差反向传导来训练人工神经网络有效解决了异或回路问题，使得训练多层神经网络称为可能；<br>1985年，Rumelhart和McClelland提出了BP网络误差反向传播学习算法；<br>1998年，以Yann Lecun为首的研究人员实现了一个七层的卷积神经网络LeNet-5识别手写数字；<br>2006年，以Geoffrey Hinton为代表的加拿大高等研究院附属机构的研究人员开始将人工神经网络/联结主义重新包装为深度学习并进行推广；<br>2009-2012年，瑞士人工智能实验室IDSIA发展了递归神经网络和深前馈神经网络；<br>2012年，Geoffrey Hinton组的研究人员在ImageNet2012上夺冠，他们的图像分类效果远远超过了第二名，深度学习热潮由此开始一直持续到现在；</p><p><img src="/2018/05/29/从ANN到CNN/ANN.png" alt="ANN"><br>对于人工神经网络，你可以简单的理解成上面的很多神经元或者感知机的结合。</p><p>现在，我相信我们大家都很熟悉什么是ANN了，但是在ANN中有什么问题么？仔细回想一下就会发现，我们的ANN都是把上一级的输出当做下一级的输入，中间的处理并不会把一个一街函数升级成二阶函数。激活函数（Activation functions）对于人工神经网络模型去学习、理解非常复杂和非线性的函数来说具有十分重要的作用。它们将非线性特性引入到我们的网络中。其主要目的是将ANN模型中一个节点的输入信号转换成一个输出信号。该输出信号现在被用作堆叠中下一个层的输入。</p><p><strong><em>PS:这里有个问题：为什么多层感知机已经可以解决异或问题了还需要BP神经网络，卷积神经网络？</em></strong><br>如果你和我一样有过同样的疑问的话，这里我们可以握个抓，毕竟都是被网上的博客和视频坑过的，推荐还是看本权威的，比如周志华老师的西瓜书《机器学习》。<br>好，我们回到问题本身，我们有必要有个基本的概念：所谓的神经网络其实就是有众多神经元构成的多层感知器，我们所说的“BP网络”，或者“卷积网络”，就是用BP（Back Propagation）的算法思维，和卷积（Convolution）的算法思维来训练我们的网络（BP主要用来更新权重）从而得到我们的目标<strong>多层感知器模型</strong>。</p><h1 id="顺利入坑"><a href="#顺利入坑" class="headerlink" title="顺利入坑"></a>顺利入坑</h1><p>如果看到了这里，恭喜你，已经入坑了，已经有了最基本的概念了，那么让我们继续修行。</p><h2 id="什么是异或，线性可分与不可分问题？"><a href="#什么是异或，线性可分与不可分问题？" class="headerlink" title="什么是异或，线性可分与不可分问题？"></a>什么是异或，线性可分与不可分问题？</h2><p><strong>首先你要理解什么是线性与非线性</strong>。有时候吧，会觉得中文翻译的东西总是缺了一点点的味道，比如说这个<strong>线性</strong>，英文是 <strong>linear</strong> ，如果你查一下这个单词，就会知道它其实表示的意思是：“一次的，线性的”；而中文的翻译只保留的“线性”这层含义，去掉了“一次”；这样的结果就是大部分大学老师也很少去强调线性这个词的一次的含义。所以现在你通过这个单词就可以知道，其实线性问题就是一次函数问题，也就是所有的未知量的次数都不大于1。而次数大于1的函数问题，就是非线性问题。这里的异或就属于非线性问题的代表。<br>在数字逻辑中，异或是对两个运算元的一种逻辑分析类型，符号为XOR或EOR或⊕。与一般的或（OR）不同，当两两数值相同时为否，而数值不同时为真。异或的真值表如下：<br>我们看下图的异或运算的真值表:<br><img src="/2018/05/29/从ANN到CNN/xorsheet.png" alt="xor"><br>据说在人工神经网络（artificial neural network, ANN）发展初期，由于无法实现对多层神经网络（包括异或逻辑）的训练而造成了一场ANN危机，到最后BP算法的出现，才让训练带有隐藏层的多层神经网络成为可能。因此异或的实现在ANN的发展史是也是具有里程碑意义的。异或之所以重要，是因为它相对于其他逻辑关系，例如与（AND）, 或（OR）等，异或是线性不可分的。如下图：<br><img src="/2018/05/29/从ANN到CNN/xor.png" alt="xor"><br>可以知道的是，最后这幅图中的两类点，是不能通过一条直线划分开的。这个直线代表的就是线性分类器，而单层感知机只是各类线性分类器中的一种，所以至此，我们也知道了，为什么线性分类器不能解决异或问题。<br>机器学习中首先要实现的就是逻辑门。这也是组成数字信号，和程序的基本单元。我们知道逻辑门中有：<br><strong>与门(AND)，或门(OR)，非门(NOT)，与非门(NAND)，或非门(NOR)，同或门(XNOR)，异或门(XOR)。</strong><br>在机器学习中，AND（与），NOR（或非）和 OR（或）的组合可以实现XNOR（同或）问题，而（XNOR）同或刚好与XOR相反。<br>还记的上面的真值表么，表中的相同颜色的点并不能以一条直线分隔开，因为我们的单层感知机也是线性分类器，所以也是无法分开这两者的，所以我们需要设计一种工具是的它可以辅助感知机分离XOR问题，所以到这里我们需要意识到一点，就是不论我们如何设计我们的神经网络，如果不能把 <strong>“输出”是“输入”的线性相关函数</strong> 这一点改变，我们的网络是永远不能处理异或这类非线性问题的，而输入是输入的次数是无法控制的，权值并不能改变函数的线性相关性，所以只能从输出这一部分入手。所以也就有了在输出层前引入 <strong>激活函数（Activation Function）</strong> 这个概念。</p><h2 id="激活函数-The-Activation-Function"><a href="#激活函数-The-Activation-Function" class="headerlink" title="激活函数 (The Activation Function)"></a>激活函数 (The Activation Function)</h2><p>在神经网络中，<strong>激活函数的作用是能够给神经网络加入一些非线性因素，使得神经网络可以更好地解决较为复杂的问题</strong>。这个Activation Function翻译过来叫做激活函数，一开始的时候我真的以为它是要激活什么东西，比如前面各层神经元或者感知器的输出到达某个值以后才出发什么东西之类的，但是实际的函数结构就是用来将原函数映射到某个区间的工具。然后使得本来是线性的函数可以升次或者降次，从而得到非线性函数以方便处理非线性的复杂分类问题。接下来我们来深度剖析一下激活函数。<br><img src="/2018/05/29/从ANN到CNN/activate.png" alt="activate"><br>当然这个图，看起来会头大，这大概是毫无疑问的，但等你明白了激活函数的意义，你就会发现它真的简单概括了激活函数的作用。</p><p>我们看一下常用的激活函数:</p><ul><li>$\boldsymbol {sigmoid\ funtion}$也叫 $\boldsymbol {Logistic\ function}$ 取值范围(0,1)<script type="math/tex; mode=display">f(z) = \frac{1}{1+e^{-x}}</script><img src="/2018/05/29/从ANN到CNN/sigmoid.png" alt="sigmoid"></li><li>$\boldsymbol {tanh\ function}$<script type="math/tex; mode=display">f(z) = tanh(z) = \frac{sinh(x)}{cosh(x)} = \frac{e^{z}-e^{-z}}{e^{z}+e^{-z}}</script>其中<script type="math/tex; mode=display">sinh(x) = \frac{e^{x}-e^{-x}}{2}; cosh(x) = \frac{e^{x}+e^{-x}}{2}</script><img src="/2018/05/29/从ANN到CNN/Tanh.png" alt="tanh"></li><li>$\boldsymbol {ReLU\ function (Rectified Linear Unit)}$<script type="math/tex; mode=display">\phi(x) = max(0, x)</script><img src="/2018/05/29/从ANN到CNN/relu.png" alt="relu"></li><li>$\boldsymbol {softmax\ function}$<script type="math/tex; mode=display">\sigma(z)_{j} = \frac{e^{z}j}{\sum^{K}_{k=1}e^{z}k}</script><img src="/2018/05/29/从ANN到CNN/softmax.png" alt="softmax"></li></ul><p><strong>上述函数的用处以及优缺点我们后面会讲到</strong><br>在实际应用中，我们还会涉及到以下的一些概念：</p><ol><li>饱和<br>当一个激活函数h(x)满足 $\lim_{x \to +\infty}h’(x) = 0$时我们称之为右饱和。</li></ol><p>当一个激活函数h(x)满足$\lim_{x \to -\infty}h’(x) = 0$时我们称之为左饱和。当一个激活函数，既满足左饱和又满足又饱和时，我们称之为饱和。</p><ol><li>硬饱和与软饱和<br>对任意的$x$，如果存在常数$c$，当$x&gt;c$时恒有$h’(x)=0$则称其为右硬饱和，当$x&lt;c$时恒 有$h’(x)=0$则称其为左硬饱和。若既满足左硬饱和，又满足右硬饱和，则称这种激活函数为硬饱和。但如果只有在极限状态下偏导数等于0的函数，称之为软饱和。</li></ol><h1 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h1><ol><li><a href="./https://www.zhihu.com/question/22334626/answer/21036590">激活函数的作用</a></li><li><a href="./http://ufldl.stanford.edu/wiki/index.php/Neural_Networks">神经网络</a></li><li><a href="./https://en.wikipedia.org/wiki/Perceptron">感知器</a><h1 id="代码实现"><a href="#代码实现" class="headerlink" title="代码实现"></a>代码实现</h1><h2 id="用Python实现感知器规则"><a href="#用Python实现感知器规则" class="headerlink" title="用Python实现感知器规则"></a>用Python实现感知器规则</h2></li></ol><p>题目：假设平面坐标系上有几个点(２,3), (4,５), (５,３)这三个点的标签为1，(０,1)，(1,1)这两个点的标签为-1,构建神经网络来分类</p><p>思路：</p><ul><li>构造神经元-单层感知器，有三个输入节点 (1,2,3),(1,4,5), (1,1,1)</li><li>对应的数据标签为(1,1,-1)</li><li>初始化权重值 $w<em>{0}$,$w</em>{1}$,$w_{2}$为-1到1之间的随机数</li><li>学习率设置为0.11</li><li>激活函数为$Sign$函数</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line">n = <span class="number">0</span>            <span class="comment">#迭代次数</span></span><br><span class="line">lr = <span class="number">0.11</span>        <span class="comment">#学习速率</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 输入数据</span></span><br><span class="line">X = np.array([[<span class="number">1</span>,<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>],</span><br><span class="line">              [<span class="number">1</span>,<span class="number">1</span>,<span class="number">4</span>,<span class="number">5</span>],</span><br><span class="line">              [<span class="number">1</span>,<span class="number">1</span>,<span class="number">1</span>,<span class="number">1</span>],</span><br><span class="line">              [<span class="number">1</span>,<span class="number">1</span>,<span class="number">5</span>,<span class="number">3</span>],</span><br><span class="line">              [<span class="number">1</span>,<span class="number">1</span>,<span class="number">0</span>,<span class="number">1</span>]])</span><br><span class="line"><span class="comment"># 标签</span></span><br><span class="line">Y = np.array([<span class="number">1</span>,<span class="number">1</span>,<span class="number">-1</span>,<span class="number">1</span>,<span class="number">-1</span>])</span><br><span class="line"></span><br><span class="line"><span class="comment"># 权重初始化，取值范围-1到1</span></span><br><span class="line">W = (np.random.random(X.shape[<span class="number">1</span>])<span class="number">-0.5</span>)*<span class="number">2</span></span><br><span class="line">print(<span class="string">'初始化权值：'</span>,W)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_show</span><span class="params">()</span>:</span></span><br><span class="line">    <span class="comment"># 所有样本的坐标</span></span><br><span class="line">    all_x = X[:, <span class="number">2</span>]</span><br><span class="line">    all_y = X[:, <span class="number">3</span>]</span><br><span class="line">    <span class="comment"># 额外注释标签为-1的负样本的坐标</span></span><br><span class="line">    all_negative_x = [<span class="number">1</span>, <span class="number">0</span>]</span><br><span class="line">    all_negative_y = [<span class="number">1</span>, <span class="number">1</span>]</span><br><span class="line">    <span class="comment"># 计算分界线斜率与截距</span></span><br><span class="line">    k = -W[<span class="number">2</span>] / W[<span class="number">3</span>]</span><br><span class="line">    b = -(W[<span class="number">0</span>] +W[<span class="number">1</span>])/ W[<span class="number">3</span>]</span><br><span class="line">    print(<span class="string">'斜率 k='</span>, k)</span><br><span class="line">    print(<span class="string">'截距 b='</span>, b)</span><br><span class="line">    print(<span class="string">'分割线函数：y = '</span>, k,<span class="string">'x +('</span>, b, <span class="string">')'</span>)</span><br><span class="line">    xdata = np.linspace(<span class="number">0</span>, <span class="number">5</span>)</span><br><span class="line">    plt.figure()</span><br><span class="line">    plt.plot(xdata,xdata*k+b,<span class="string">'r'</span>)</span><br><span class="line">    plt.plot(all_x, all_y,<span class="string">'bo'</span>)</span><br><span class="line">    plt.plot(all_negative_x, all_negative_y, <span class="string">'yo'</span>)</span><br><span class="line">    plt.show()</span><br><span class="line"></span><br><span class="line"><span class="comment">#更新权值函数</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_update</span><span class="params">()</span>:</span></span><br><span class="line">    <span class="keyword">global</span> X,Y,W,lr,n</span><br><span class="line">    n += <span class="number">1</span></span><br><span class="line">    <span class="comment">#新输出：X与W的转置相乘，得到的结果再由阶跃函数处理，得到新输出</span></span><br><span class="line">    new_output = np.sign(np.dot(X,W.T))</span><br><span class="line">    <span class="comment">#调整权重: 新权重 = 旧权重 + 改变权重</span></span><br><span class="line">    new_W = W + lr*((Y-new_output.T).dot(X))/int(X.shape[<span class="number">0</span>])</span><br><span class="line">    W = new_W</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">main</span><span class="params">()</span>:</span></span><br><span class="line">    <span class="keyword">for</span> _ <span class="keyword">in</span> range(<span class="number">100</span>):</span><br><span class="line">        get_update()</span><br><span class="line">        print(<span class="string">'第'</span>,n,<span class="string">'次改变后的权重：'</span>,W)</span><br><span class="line">        new_output = np.sign(np.dot(X, W.T))</span><br><span class="line">        <span class="keyword">if</span> (new_output == Y.T).all():</span><br><span class="line">            print(<span class="string">"迭代次数："</span>, n)</span><br><span class="line">            <span class="keyword">break</span></span><br><span class="line">    get_show()</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">"__main__"</span>:</span><br><span class="line">    main()</span><br></pre></td></tr></table></figure><p>输出结果为：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">初始化权值： [ <span class="number">0.71761357</span> <span class="number">-0.01222642</span>  <span class="number">0.86193314</span>  <span class="number">0.16775246</span>]</span><br><span class="line">第 <span class="number">1</span> 次改变后的权重： [ <span class="number">0.62961357</span> <span class="number">-0.10022642</span>  <span class="number">0.81793314</span>  <span class="number">0.07975246</span>]</span><br><span class="line">第 <span class="number">2</span> 次改变后的权重： [ <span class="number">0.54161357</span> <span class="number">-0.18822642</span>  <span class="number">0.77393314</span> <span class="number">-0.00824754</span>]</span><br><span class="line">第 <span class="number">3</span> 次改变后的权重： [ <span class="number">0.45361357</span> <span class="number">-0.27622642</span>  <span class="number">0.72993314</span> <span class="number">-0.09624754</span>]</span><br><span class="line">第 <span class="number">4</span> 次改变后的权重： [ <span class="number">0.36561357</span> <span class="number">-0.36422642</span>  <span class="number">0.68593314</span> <span class="number">-0.18424754</span>]</span><br><span class="line">第 <span class="number">5</span> 次改变后的权重： [ <span class="number">0.32161357</span> <span class="number">-0.40822642</span>  <span class="number">0.64193314</span> <span class="number">-0.22824754</span>]</span><br><span class="line">第 <span class="number">6</span> 次改变后的权重： [ <span class="number">0.27761357</span> <span class="number">-0.45222642</span>  <span class="number">0.59793314</span> <span class="number">-0.27224754</span>]</span><br><span class="line">第 <span class="number">7</span> 次改变后的权重： [ <span class="number">0.23361357</span> <span class="number">-0.49622642</span>  <span class="number">0.55393314</span> <span class="number">-0.31624754</span>]</span><br><span class="line">第 <span class="number">8</span> 次改变后的权重： [ <span class="number">0.27761357</span> <span class="number">-0.45222642</span>  <span class="number">0.64193314</span> <span class="number">-0.18424754</span>]</span><br><span class="line">第 <span class="number">9</span> 次改变后的权重： [ <span class="number">0.23361357</span> <span class="number">-0.49622642</span>  <span class="number">0.59793314</span> <span class="number">-0.22824754</span>]</span><br><span class="line">第 <span class="number">10</span> 次改变后的权重： [ <span class="number">0.18961357</span> <span class="number">-0.54022642</span>  <span class="number">0.55393314</span> <span class="number">-0.27224754</span>]</span><br><span class="line">第 <span class="number">11</span> 次改变后的权重： [ <span class="number">0.23361357</span> <span class="number">-0.49622642</span>  <span class="number">0.64193314</span> <span class="number">-0.14024754</span>]</span><br><span class="line">第 <span class="number">12</span> 次改变后的权重： [ <span class="number">0.18961357</span> <span class="number">-0.54022642</span>  <span class="number">0.59793314</span> <span class="number">-0.18424754</span>]</span><br><span class="line">第 <span class="number">13</span> 次改变后的权重： [ <span class="number">0.14561357</span> <span class="number">-0.58422642</span>  <span class="number">0.55393314</span> <span class="number">-0.22824754</span>]</span><br><span class="line">第 <span class="number">14</span> 次改变后的权重： [ <span class="number">0.18961357</span> <span class="number">-0.54022642</span>  <span class="number">0.64193314</span> <span class="number">-0.09624754</span>]</span><br><span class="line">第 <span class="number">15</span> 次改变后的权重： [ <span class="number">0.14561357</span> <span class="number">-0.58422642</span>  <span class="number">0.59793314</span> <span class="number">-0.14024754</span>]</span><br><span class="line">第 <span class="number">16</span> 次改变后的权重： [ <span class="number">0.10161357</span> <span class="number">-0.62822642</span>  <span class="number">0.55393314</span> <span class="number">-0.18424754</span>]</span><br><span class="line">迭代次数： <span class="number">16</span></span><br><span class="line">斜率 k= <span class="number">3.0064615780789095</span></span><br><span class="line">截距 b= <span class="number">-2.8581812250111303</span></span><br><span class="line">分割线函数：y =  <span class="number">3.0064615780789095</span> x +( <span class="number">-2.8581812250111303</span> )</span><br></pre></td></tr></table></figure></p><p><img src="/2018/05/29/从ANN到CNN/python0.png" alt="percptron"></p><h2 id="异或问题-增加非线性项"><a href="#异或问题-增加非线性项" class="headerlink" title="异或问题-增加非线性项"></a>异或问题-增加非线性项</h2><p>异或问题不是线性可以求解的，解决方式有增加非线性项。<br>问题例如：平面上的点(0,0), (1,1) 对应的数据标签为-1，平面上的点(0,1), (1,0) 对应的数据标签为 1，构造单层感知器以区分两类数据点。<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">'''</span></span><br><span class="line"><span class="string">异或问题的解决方式有：增加非线性项:</span></span><br><span class="line"><span class="string">     输入x1,x2；</span></span><br><span class="line"><span class="string">     增加x1^2,x1*x2,x2^2</span></span><br><span class="line"><span class="string">'''</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line">n = <span class="number">0</span>            <span class="comment">#迭代次数</span></span><br><span class="line">lr = <span class="number">0.11</span>        <span class="comment">#学习速率</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#输入数据分别:偏置值,x1,x2,x1^2,x1*x2,x2^2</span></span><br><span class="line">X = np.array([[<span class="number">1</span>,<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>],</span><br><span class="line">              [<span class="number">1</span>,<span class="number">0</span>,<span class="number">1</span>,<span class="number">0</span>,<span class="number">0</span>,<span class="number">1</span>],</span><br><span class="line">              [<span class="number">1</span>,<span class="number">1</span>,<span class="number">0</span>,<span class="number">1</span>,<span class="number">0</span>,<span class="number">0</span>],</span><br><span class="line">              [<span class="number">1</span>,<span class="number">1</span>,<span class="number">1</span>,<span class="number">1</span>,<span class="number">1</span>,<span class="number">1</span>]])</span><br><span class="line"></span><br><span class="line"><span class="comment">#标签</span></span><br><span class="line">Y = np.array([<span class="number">-1</span>,<span class="number">1</span>,<span class="number">1</span>,<span class="number">-1</span>])</span><br><span class="line"></span><br><span class="line"><span class="comment"># 权重初始化，取值范围-1到1</span></span><br><span class="line">W = (np.random.random(X.shape[<span class="number">1</span>])<span class="number">-0.5</span>)*<span class="number">2</span></span><br><span class="line">print(<span class="string">'初始化权值：'</span>,W)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_show</span><span class="params">()</span>:</span></span><br><span class="line">    <span class="comment"># 正样本</span></span><br><span class="line">    x1 = [<span class="number">0</span>, <span class="number">1</span>]</span><br><span class="line">    y1 = [<span class="number">1</span>, <span class="number">0</span>]</span><br><span class="line">    <span class="comment"># 负样本</span></span><br><span class="line">    x2 = [<span class="number">0</span>,<span class="number">1</span>]</span><br><span class="line">    y2 = [<span class="number">0</span>,<span class="number">1</span>]</span><br><span class="line">    xdata = np.linspace(<span class="number">-1</span>, <span class="number">2</span>)</span><br><span class="line">    plt.figure()</span><br><span class="line">    plt.plot(xdata, get_line(xdata,<span class="number">1</span>), <span class="string">'r'</span>)</span><br><span class="line">    plt.plot(xdata, get_line(xdata,<span class="number">2</span>), <span class="string">'r'</span>)</span><br><span class="line">    plt.plot(x1, y1, <span class="string">'bo'</span>)</span><br><span class="line">    plt.plot(x2, y2, <span class="string">'yo'</span>)</span><br><span class="line">    plt.show()</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_line</span><span class="params">(x,root)</span>:</span></span><br><span class="line">    a = W[<span class="number">5</span>]</span><br><span class="line">    b = W[<span class="number">2</span>] + x*W[<span class="number">4</span>]</span><br><span class="line">    c = W[<span class="number">0</span>] + x*W[<span class="number">1</span>] + x*x*W[<span class="number">3</span>]</span><br><span class="line">    <span class="keyword">if</span> root == <span class="number">1</span>:</span><br><span class="line">        <span class="keyword">return</span> (-b+np.sqrt(b*b<span class="number">-4</span>*a*c))/(<span class="number">2</span>*a)</span><br><span class="line">    <span class="keyword">if</span> root == <span class="number">2</span>:</span><br><span class="line">        <span class="keyword">return</span> (-b-np.sqrt(b*b<span class="number">-4</span>*a*c))/(<span class="number">2</span>*a)</span><br><span class="line"></span><br><span class="line"><span class="comment">#更新权值函数</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_update</span><span class="params">()</span>:</span></span><br><span class="line">    <span class="keyword">global</span> X,Y,W,lr,n</span><br><span class="line">    n += <span class="number">1</span></span><br><span class="line">    <span class="comment">#新输出：X与W的转置相乘，得到的结果再由阶跃函数处理，得到新输出</span></span><br><span class="line">    new_output = np.dot(X,W.T)</span><br><span class="line">    <span class="comment">#调整权重: 新权重 = 旧权重 + 改变权重</span></span><br><span class="line">    new_W = W + lr*((Y-new_output.T).dot(X))/int(X.shape[<span class="number">0</span>])</span><br><span class="line">    W = new_W</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">main</span><span class="params">()</span>:</span></span><br><span class="line">    <span class="keyword">for</span> _ <span class="keyword">in</span> range(<span class="number">10000</span>):</span><br><span class="line">        get_update()</span><br><span class="line">    get_show()</span><br><span class="line">    last_output = np.dot(X,W.T)</span><br><span class="line">    print(<span class="string">'最后逼近值：'</span>,last_output)</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">"__main__"</span>:</span><br><span class="line">    main()</span><br></pre></td></tr></table></figure></p><p><strong>输出结果：</strong><br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">初始化权值： [ 0.53493581  0.84054602 -0.49422516  0.86122222 -0.84342568 -0.57384193]</span><br><span class="line">最后逼近值： [-1.  1.  1. -1.]</span><br></pre></td></tr></table></figure></p><p>图像：<br><img src="/2018/05/29/从ANN到CNN/python1.png" alt="python1.png"></p><h2 id="Python实现简单的感知器学习规则以分类鸢尾花数据集分类。"><a href="#Python实现简单的感知器学习规则以分类鸢尾花数据集分类。" class="headerlink" title="Python实现简单的感知器学习规则以分类鸢尾花数据集分类。"></a>Python实现简单的感知器学习规则以分类鸢尾花数据集分类。</h2><p>我们将从<a href="https://link.jianshu.com/?t=http%3A%2F%2Farchive.ics.uci.edu%2Fml%2F" target="_blank" rel="noopener">UCI Machine Learning Repository</a>载入鸢尾花数据集，并只关注Setosa 和Versicolor两种花。此外，为了可视化，我们将只使用两种特性：萼片长度（sepal length ）和花片长度（petal length）。<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">from</span> mlxtend.plotting <span class="keyword">import</span> plot_decision_regions</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Perceptron</span><span class="params">(object)</span>:</span></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, eta=<span class="number">0.01</span>, epochs=<span class="number">50</span>)</span>:</span></span><br><span class="line">    self.eta = eta</span><br><span class="line">    self.epochs = epochs</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">train</span><span class="params">(self, X, y)</span>:</span></span><br><span class="line">    self.w_ = np.zeros(<span class="number">1</span> + X.shape[<span class="number">1</span>])</span><br><span class="line">    self.errors_ = []</span><br><span class="line">    <span class="keyword">for</span> _ <span class="keyword">in</span> range(self.epochs):</span><br><span class="line">      errors = <span class="number">0</span></span><br><span class="line">      <span class="keyword">for</span> xi, target <span class="keyword">in</span> zip(X, y):</span><br><span class="line">        update = self.eta * (target - self.predict(xi))</span><br><span class="line">        self.w_[<span class="number">1</span>:] +=  update * xi</span><br><span class="line">        self.w_[<span class="number">0</span>] +=  update</span><br><span class="line">        errors += int(update != <span class="number">0.0</span>)</span><br><span class="line">      self.errors_.append(errors)</span><br><span class="line">    <span class="keyword">return</span> self</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">net_input</span><span class="params">(self, X)</span>:</span></span><br><span class="line">    <span class="keyword">return</span> np.dot(X, self.w_[<span class="number">1</span>:]) + self.w_[<span class="number">0</span>]</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">predict</span><span class="params">(self, X)</span>:</span></span><br><span class="line">    <span class="keyword">return</span> np.where(self.net_input(X) &gt;= <span class="number">0.0</span>, <span class="number">1</span>, <span class="number">-1</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">df = pd.read_csv(<span class="string">'https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data'</span>, header=<span class="keyword">None</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># setosa and versicolor</span></span><br><span class="line">y = df.iloc[<span class="number">0</span>:<span class="number">100</span>, <span class="number">4</span>].values</span><br><span class="line">y = np.where(y == <span class="string">'Iris-setosa'</span>, <span class="number">-1</span>, <span class="number">1</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># sepal length and petal length</span></span><br><span class="line">X = df.iloc[<span class="number">0</span>:<span class="number">100</span>, [<span class="number">0</span>,<span class="number">2</span>]].values</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">ppn = Perceptron(epochs=<span class="number">10</span>, eta=<span class="number">0.1</span>)</span><br><span class="line">ppn.train(X, y)</span><br><span class="line">print(<span class="string">'Weights: %s'</span> % ppn.w_)</span><br><span class="line"></span><br><span class="line">plot_decision_regions(X, y, clf=ppn)</span><br><span class="line">plt.title(<span class="string">'Perceptron'</span>)</span><br><span class="line">plt.xlabel(<span class="string">'sepal length [cm]'</span>)</span><br><span class="line">plt.ylabel(<span class="string">'petal length [cm]'</span>)</span><br><span class="line">plt.show()</span><br><span class="line"></span><br><span class="line">plt.plot(range(<span class="number">1</span>, len(ppn.errors_)+<span class="number">1</span>), ppn.errors_, marker=<span class="string">'o'</span>)</span><br><span class="line">plt.xlabel(<span class="string">'Iterations'</span>)</span><br><span class="line">plt.ylabel(<span class="string">'Missclassifications'</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure></p><p><strong>输出：</strong><br>Weights: [-0.4  -0.68  1.82]<br><strong>图像：</strong><br><img src="/2018/05/29/从ANN到CNN/python2.png" alt="python2"><br><img src="/2018/05/29/从ANN到CNN/python3.png" alt="python3"></p><h2 id="感知器存在的问题"><a href="#感知器存在的问题" class="headerlink" title="感知器存在的问题"></a>感知器存在的问题</h2><ul><li>尽管感知器完美地分辨出两种鸢尾花类，但收敛是感知器的最大问题之一。 Frank Rosenblatt在数学上证明了当两个类可由线性超平面分离时，感知器的学习规则收敛，但当类无法由线性分类器完美分离时，问题就出现了。为了说明这个问题，我们将使用鸢尾花数据集中两个不同的类和特性。</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">from</span> mlxtend.plotting <span class="keyword">import</span> plot_decision_regions</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Perceptron</span><span class="params">(object)</span>:</span></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, eta=<span class="number">0.01</span>, epochs=<span class="number">50</span>)</span>:</span></span><br><span class="line">    self.eta = eta</span><br><span class="line">    self.epochs = epochs</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">train</span><span class="params">(self, X, y)</span>:</span></span><br><span class="line">    self.w_ = np.zeros(<span class="number">1</span> + X.shape[<span class="number">1</span>])</span><br><span class="line">    self.errors_ = []</span><br><span class="line">    <span class="keyword">for</span> _ <span class="keyword">in</span> range(self.epochs):</span><br><span class="line">      errors = <span class="number">0</span></span><br><span class="line">      <span class="keyword">for</span> xi, target <span class="keyword">in</span> zip(X, y):</span><br><span class="line">        update = self.eta * (target - self.predict(xi))</span><br><span class="line">        self.w_[<span class="number">1</span>:] +=  update * xi</span><br><span class="line">        self.w_[<span class="number">0</span>] +=  update</span><br><span class="line">        errors += int(update != <span class="number">0.0</span>)</span><br><span class="line">      self.errors_.append(errors)</span><br><span class="line">    <span class="keyword">return</span> self</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">net_input</span><span class="params">(self, X)</span>:</span></span><br><span class="line">    <span class="keyword">return</span> np.dot(X, self.w_[<span class="number">1</span>:]) + self.w_[<span class="number">0</span>]</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">predict</span><span class="params">(self, X)</span>:</span></span><br><span class="line">    <span class="keyword">return</span> np.where(self.net_input(X) &gt;= <span class="number">0.0</span>, <span class="number">1</span>, <span class="number">-1</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">df = pd.read_csv(<span class="string">'https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data'</span>, header=<span class="keyword">None</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># versicolor and virginica</span></span><br><span class="line">y2 = df.iloc[<span class="number">50</span>:<span class="number">150</span>, <span class="number">4</span>].values</span><br><span class="line">y2 = np.where(y2 == <span class="string">'Iris-virginica'</span>, <span class="number">-1</span>, <span class="number">1</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># sepal width and petal width</span></span><br><span class="line">X2 = df.iloc[<span class="number">50</span>:<span class="number">150</span>, [<span class="number">1</span>,<span class="number">3</span>]].values</span><br><span class="line"></span><br><span class="line">ppn = Perceptron(epochs=<span class="number">25</span>, eta=<span class="number">0.01</span>)</span><br><span class="line">ppn.train(X2, y2)</span><br><span class="line"></span><br><span class="line">plot_decision_regions(X2, y2, clf=ppn)</span><br><span class="line">plt.show()</span><br><span class="line"></span><br><span class="line">plt.plot(range(<span class="number">1</span>, len(ppn.errors_)+<span class="number">1</span>), ppn.errors_, marker=<span class="string">'o'</span>)</span><br><span class="line">plt.xlabel(<span class="string">'Iterations'</span>)</span><br><span class="line">plt.ylabel(<span class="string">'Missclassifications'</span>)</span><br><span class="line">plt.show()</span><br><span class="line">print(<span class="string">'Total number of misclassifications: %d of 100'</span> % (y2 != ppn.predict(X2)).sum())</span><br></pre></td></tr></table></figure><p><strong>输出：</strong><br><code>Total number of misclassifications: 43 of 100</code><br><img src="/2018/05/29/从ANN到CNN/python4.png" alt="python4"><br><img src="/2018/05/29/从ANN到CNN/python5.png" alt="python5"></p><ul><li>在较低的学习率情形下，因为一个或多个样本在每一次迭代总是无法被分类造成学习规则不停更新权值，最终，感知器还是无法找到一个好的决策边界。</li><li>感知器算法的另一个缺陷是，一旦所有样本均被正确分类，它就会停止更新权值，这看起来有些矛盾。直觉告诉我们，具有大间隔的决策面（如下图中虚线所示）比感知器的决策面具有更好的分类误差。但是诸如“Support Vector Machines”之类的大间隔分类器不在本次讨论范围。<br><img src="/2018/05/29/从ANN到CNN/python6.png" alt="python6"></li></ul>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;&lt;strong&gt;写在前面：&lt;/strong&gt; 或许机器学习这部分内容不应该就这么展开，应该循序渐进，待自己有了深层次了解以后，从基本的回归、分类讲起，但是最后还是选择了边学习边总结的形式，至少能详细记录自己曾经踩过的坑，记录自己的学习路线，也算是个好的形式吧！&lt;/p&gt;
&lt;h
      
    
    </summary>
    
      <category term="人工智能" scheme="https://stonema.github.io/categories/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/"/>
    
      <category term="机器学习" scheme="https://stonema.github.io/categories/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
    
      <category term="神经网络" scheme="https://stonema.github.io/tags/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/"/>
    
      <category term="ANN" scheme="https://stonema.github.io/tags/ANN/"/>
    
      <category term="神经元" scheme="https://stonema.github.io/tags/%E7%A5%9E%E7%BB%8F%E5%85%83/"/>
    
      <category term="感知器" scheme="https://stonema.github.io/tags/%E6%84%9F%E7%9F%A5%E5%99%A8/"/>
    
      <category term="Perceptron" scheme="https://stonema.github.io/tags/Perceptron/"/>
    
  </entry>
  
  <entry>
    <title>深入浅出OpenGL</title>
    <link href="https://stonema.github.io/2018/05/21/%E6%B7%B1%E5%85%A5%E6%B5%85%E5%87%BAOpenGL/"/>
    <id>https://stonema.github.io/2018/05/21/深入浅出OpenGL/</id>
    <published>2018-05-21T01:00:36.000Z</published>
    <updated>2020-01-18T01:45:05.208Z</updated>
    
    <content type="html"><![CDATA[<!-- omit in toc --><h1 id="OpenGL概述"><a href="#OpenGL概述" class="headerlink" title="OpenGL概述"></a>OpenGL概述</h1><h2 id="什么是OpenGL？"><a href="#什么是OpenGL？" class="headerlink" title="什么是OpenGL？"></a>什么是OpenGL？</h2><p>OpenGL是一种应用程序的编程接口(Application Programming Interface, API)，它是一种可以对图形硬件设备特性进行访问的软件库。<br>《OpenGL编程指南》</p><h2 id="OpenGL的工作流："><a href="#OpenGL的工作流：" class="headerlink" title="OpenGL的工作流："></a>OpenGL的工作流：</h2><p>OpenGL主要工作就是将二维及三维物体绘制到帧缓存器中</p><h3 id="主要步骤："><a href="#主要步骤：" class="headerlink" title="主要步骤："></a>主要步骤：</h3><ol><li>构造几何要素（点，线，多边形），创建对象的数学描述。在三维空间中放置对象。</li><li>计算对象的颜色，颜色可以给出，或由光照条件及纹理间接给出。</li><li>光栅化，把对象的数字描述和颜色信息转换为屏幕上的像素。</li></ol>]]></content>
    
    <summary type="html">
    
      
      
        &lt;!-- omit in toc --&gt;
&lt;h1 id=&quot;OpenGL概述&quot;&gt;&lt;a href=&quot;#OpenGL概述&quot; class=&quot;headerlink&quot; title=&quot;OpenGL概述&quot;&gt;&lt;/a&gt;OpenGL概述&lt;/h1&gt;&lt;h2 id=&quot;什么是OpenGL？&quot;&gt;&lt;a href=
      
    
    </summary>
    
      <category term="OpenGL编程" scheme="https://stonema.github.io/categories/OpenGL%E7%BC%96%E7%A8%8B/"/>
    
    
      <category term="OpenGL" scheme="https://stonema.github.io/tags/OpenGL/"/>
    
      <category term="图形图像" scheme="https://stonema.github.io/tags/%E5%9B%BE%E5%BD%A2%E5%9B%BE%E5%83%8F/"/>
    
  </entry>
  
  <entry>
    <title>进军OpenCV和OpenGL</title>
    <link href="https://stonema.github.io/2018/05/16/%E8%BF%9B%E5%86%9BOpenCV%E5%92%8COpenGL/"/>
    <id>https://stonema.github.io/2018/05/16/进军OpenCV和OpenGL/</id>
    <published>2018-05-16T02:54:49.000Z</published>
    <updated>2020-01-18T01:45:05.225Z</updated>
    
    <content type="html"><![CDATA[<p>近期开始做OpenCV和OpenGL方向的研究与开发工作了，感谢my的书卡，感谢GitHub和机械工业出版社，带我入门，带我编程，能够从一个门外汉进入这个领域。</p><hr><h2 id="OpenCV简介"><a href="#OpenCV简介" class="headerlink" title="OpenCV简介"></a>OpenCV简介</h2><p>OpenCV是一个跨平台计算机视觉库，可以运行在Linux、Windows、Android和Mac OS操作系统上运行。在没有做这方面工作之前不太明白OpenCV与OpenGL的区别。现在让我来讲的话，大概可以这么理解：<strong>OpenCV是一个算法库</strong>，它实现了很多图形处理和计算机视觉的通用算法，而<strong>OpenGL是一个图形库</strong>，它实现了一些基本的计算机图形图像，可以方便的开发二维或者三维计算机应用程序。</p><h2 id="1-Windows下配置OpenCV与VS2015集成环境"><a href="#1-Windows下配置OpenCV与VS2015集成环境" class="headerlink" title="1. Windows下配置OpenCV与VS2015集成环境"></a>1. Windows下配置OpenCV与VS2015集成环境</h2><p><strong>为了配置这个环境，中间遇到了无数的坑，一个一个解决，将这个过程中遇到的问题总结一下，写在这里。</strong><br>在做图像处理的时候，频繁使用到OpenCV中的算法，于是想系统的学习一下这方面的知识，买了一本《OpenCV By Example》照着里面的例子学习……</p><h3 id="1-1-环境："><a href="#1-1-环境：" class="headerlink" title="1.1 环境："></a>1.1 <strong>环境：</strong></h3><p><em>Windows10 x64, VS2015, OpenCV3.3.0, Cmake3.11.1</em><br>首先下载OpenCV: <a href="https://opencv.org/releases.html" target="_blank" rel="noopener">https://opencv.org/releases.html</a><br><img src="/2018/05/16/进军OpenCV和OpenGL/opencv0.png" alt="opencv"><br>Documentation是OpenCV的使用手册，source是源码，Win pack是编译后的opencv自解压包，我们这里可以选择下载源码或者下载编译后的自解压包。二者最基本的区别就是：前者需要我们本地编译，后者可以直接使用。我们将两个文件都下载下来:<br><img src="/2018/05/16/进军OpenCV和OpenGL/opencv1.png" alt="opencv3.3"></p><h3 id="1-2-方法一：自解压包的安装与配置"><a href="#1-2-方法一：自解压包的安装与配置" class="headerlink" title="1.2 方法一：自解压包的安装与配置"></a>1.2 方法一：自解压包的安装与配置</h3><p>下载完成后的exe文件直接运行，就是自解压过程<br><img src="/2018/05/16/进军OpenCV和OpenGL/opencv2.png" alt="exe"><br>选择好目标文件夹（<strong>这里注意路径中不要有中文</strong>），解压完成后得到如下文件：<br><img src="/2018/05/16/进军OpenCV和OpenGL/opencv3.png" alt="opencvfile"><br><strong>环境变量：</strong> 在windows的环境变量中的Path中添加opencv中的bin路径：例如我的是：C:\opencv\build\x64\vc14\bin<br><strong>vs配置：</strong> 在配置好环境变量后在VS2015中创建一个C++的win32控制台程序，然后开始配置这个项目的属性，首先在视图-&gt;其他窗口 中打开当前项目的属性管理器窗口:<br><img src="/2018/05/16/进军OpenCV和OpenGL/opencv4.png" alt="config"><br>因为我们前面配置的都是x64的环境，所以这里选择x64的Debug属性文件夹<br><img src="/2018/05/16/进军OpenCV和OpenGL/opencv5.png" alt="debug"><br>下面需要修改相关配置：</p><ol><li>VC++目录：<br>将下面的内容依次加入到VC++的包含目录(include path)<br>C:\opencv\build\include<br>C:\opencv\build\include\opencv<br>C:\opencv\build\include\opencv2<br>将下面内容依次加入到VC++库目录(lib path)<br>C:\opencv\build\x64\vc14\lib</li><li>连接器目录：<br>链接器-&gt;输入-&gt;附加依赖项<br>将下面的lib加入到其中:<br>opencv_world330d.lib<br><img src="/2018/05/16/进军OpenCV和OpenGL/opencv6.png" alt="worldd.lib"><br>这里注意的是，有些地方可能会用到opencv_ts<em>*</em>.lib但是自解压包内是不包含这个lib的，需要我们使用自己编译的程序。<br>至此，OpenCV的自解压版已经配置完毕，可以直接在工程中调用OpenCV中的函数：<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;iostream&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;string&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;sstream&gt;</span></span></span><br><span class="line"><span class="keyword">using</span> <span class="keyword">namespace</span> <span class="built_in">std</span>;</span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">"opencv2/core.hpp"</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">"opencv2/highgui.hpp"</span></span></span><br><span class="line"><span class="keyword">using</span> <span class="keyword">namespace</span> cv;</span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">mainOne</span><span class="params">()</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">Mat color = imread(<span class="string">"D:\\WorkSpace\\VSworkspace\\OpenCV\\OpencvBooks\\img\\lena.jpg"</span>);</span><br><span class="line"><span class="comment">//图片必须添加到工程目下</span></span><br><span class="line"><span class="comment">//也就是和test.cpp文件放在一个文件夹下！！！</span></span><br><span class="line">imshow(<span class="string">"测试程序"</span>, color);</span><br><span class="line">Mat gray = imread(<span class="string">"D:\\WorkSpace\\VSworkspace\\OpenCV\\OpencvBooks\\img\\lena.jpg"</span>,<span class="number">0</span>);</span><br><span class="line"><span class="comment">//写图像</span></span><br><span class="line">imwrite(<span class="string">"D:\\WorkSpace\\VSworkspace\\OpenCV\\OpencvBooks\\img\\lena.jpg"</span>, gray);</span><br><span class="line"><span class="comment">// 通过opencv函数获取相同像素</span></span><br><span class="line"><span class="keyword">int</span> myrow = color.cols - <span class="number">1</span>;</span><br><span class="line"><span class="keyword">int</span> myCol = color.rows - <span class="number">1</span>;</span><br><span class="line">Vec3b pixel = color.at&lt;Vec3b&gt;(myrow,myCol);</span><br><span class="line"><span class="built_in">cout</span> &lt;&lt; <span class="string">"Pixel value (B,G,R): ("</span> &lt;&lt; (<span class="keyword">int</span>)pixel[<span class="number">0</span>] &lt;&lt; <span class="string">","</span> &lt;&lt; (<span class="keyword">int</span>)pixel[<span class="number">1</span>] &lt;&lt; <span class="string">","</span> &lt;&lt; (<span class="keyword">int</span>)pixel[<span class="number">2</span>] &lt;&lt; <span class="string">")"</span> &lt;&lt; <span class="built_in">endl</span>;</span><br><span class="line"><span class="built_in">cout</span> &lt;&lt; color.size &lt;&lt; <span class="built_in">endl</span>; </span><br><span class="line"><span class="comment">// 初始化矩阵 </span></span><br><span class="line">Mat m = Mat::eye(<span class="number">5</span>, <span class="number">5</span>, CV_32F);</span><br><span class="line">Mat n = Mat::ones(<span class="number">5</span>,<span class="number">5</span>,CV_32F);</span><br><span class="line">Mat result = m*n;</span><br><span class="line"><span class="built_in">cout</span> &lt;&lt; m &lt;&lt; <span class="built_in">endl</span>;</span><br><span class="line"><span class="function">FileStorage <span class="title">fs</span><span class="params">(<span class="string">"test.yml"</span>, FileStorage::WRITE)</span></span>;</span><br><span class="line">fs &lt;&lt; <span class="string">"result"</span> &lt;&lt; result;</span><br><span class="line">fs.release();</span><br><span class="line">imshow(<span class="string">"Lena BGR"</span>, color);</span><br><span class="line">imshow(<span class="string">"Lena Gray"</span>, gray);</span><br><span class="line">waitKey(<span class="number">0</span>);</span><br><span class="line"><span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li></ol><h3 id="1-3-方法二：本地编译再配置"><a href="#1-3-方法二：本地编译再配置" class="headerlink" title="1.3 方法二：本地编译再配置"></a>1.3 方法二：本地编译再配置</h3><p>找到前面下载的源码版的opencv，同时下载并安装cmake工具到本机。<br>然后查看这个文件夹，可以看到有cmakelists文件，这个就是cmake需要用的构建工程的文件<br><img src="/2018/05/16/进军OpenCV和OpenGL/opencv7.png" alt="opencv7"><br>然后选择source code和要build到的文件夹：<br><img src="/2018/05/16/进军OpenCV和OpenGL/opencv8.png" alt="opencv8"><br>点击configure<br><img src="/2018/05/16/进军OpenCV和OpenGL/opencv9.png" alt="opencv9"><br>选择本机的 VS2015 Win64,然后Finish，这个过程是生成VS2015的opencv环境，并检验本机的vs环境对于opencv的必要依赖是否完整，这个过程需要一段时间,完成后，选择你需要build的文件，然后再点击Configure开始构建：<br><img src="/2018/05/16/进军OpenCV和OpenGL/opencv10.png" alt="10"><br>然后点击Generate开始生成链接库，完成后就会发现build文件夹内已经存在了opencv的工程sln。<br><img src="/2018/05/16/进军OpenCV和OpenGL/opencv11.png" alt="11"><br>然后打开这个工程，找到CMakeTargets文件夹内的ALL_BUILD，进行编译：右键-&gt;生成，这个过程持续一段时间。编译完成后，再找到CMakeTargets文件夹内的INSTALL工程，再次执行生成，这样整个OpenCV的编译工作就完成了，生成了对应的动态链接库和可执行文件。可以看到在build文件夹内的的install文件夹为编译生成的文件：<br><img src="/2018/05/16/进军OpenCV和OpenGL/opencv16.png" alt="opencv16"><br>我们对比一下编译完成的OpenCV 和官方的自解压版本中的内容：<br><img src="/2018/05/16/进军OpenCV和OpenGL/opencv17.png" alt="opencv17"><br><img src="/2018/05/16/进军OpenCV和OpenGL/opencv18.png" alt="opencv18"><br>可以看到编译版本比自解压版多一些链接库和lib文件。但是同时缺少 opencv_world***.dll 以及 opencv_world***.lib<br>后面的操作就和自解压版相同，如果需要使用编译版本的OpenCV，就需要把环境变量配置成刚刚编译好的内容，同时设置VS中的属性页即可。</p><hr><p><strong>PS:</strong> 我在前面的执行cmake的过程中，多勾选了BUILD_openc_world 和 WITH_QT 导致在VS中编译OpenCV源码的过程中出现了很多错误：<br><img src="/2018/05/16/进军OpenCV和OpenGL/opencv13.png" alt="opencv13"><br><img src="/2018/05/16/进军OpenCV和OpenGL/opencv14.png" alt="opencv14"><br><img src="/2018/05/16/进军OpenCV和OpenGL/opencv15.png" alt="opencv15"><br>至今不知道如何解决，感觉是本机的QT配置有问题。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;近期开始做OpenCV和OpenGL方向的研究与开发工作了，感谢my的书卡，感谢GitHub和机械工业出版社，带我入门，带我编程，能够从一个门外汉进入这个领域。&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&quot;OpenCV简介&quot;&gt;&lt;a href=&quot;#OpenCV简介&quot; class=&quot;he
      
    
    </summary>
    
      <category term="计算机图形学" scheme="https://stonema.github.io/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9B%BE%E5%BD%A2%E5%AD%A6/"/>
    
    
      <category term="OpenCV" scheme="https://stonema.github.io/tags/OpenCV/"/>
    
      <category term="OpenGL" scheme="https://stonema.github.io/tags/OpenGL/"/>
    
  </entry>
  
  <entry>
    <title>特征检测技术总结</title>
    <link href="https://stonema.github.io/2018/04/25/%E7%89%B9%E5%BE%81%E6%A3%80%E6%B5%8B%E6%8A%80%E6%9C%AF%E6%80%BB%E7%BB%93/"/>
    <id>https://stonema.github.io/2018/04/25/特征检测技术总结/</id>
    <published>2018-04-25T07:36:34.000Z</published>
    <updated>2020-01-18T01:45:05.209Z</updated>
    
    <content type="html"><![CDATA[<h2 id="写在前面"><a href="#写在前面" class="headerlink" title="写在前面"></a>写在前面</h2><p>对于模式识别，到了研二终于发自内心的体会到它的应用领域已经广阔到一种不可描述的状态，大到人工智能，数据挖掘，，机器学习，小到特征提取，图像处理，都会有模式识别的影子与你相随，这种感觉就像数学领域中的欧拉，拉格朗日，与柯西，爷仨~贯穿你的整个学习过程，如影随形。在读研以前，从没去思考过计算机是如何识别图片的、如何认知文字的、如何回答语音的……直到后来想做三维模型检索相关领域的内容，本以为不会是太难的东西，到后来才发现，这里面的内容足够我消化半辈子了……我这个人大概率还是脑子太笨了，最开始的时候，通过各种手段去了解图像处理，深度学习这方面的知识，很长时间以来，都没有深入理解这些内容的精髓，没有清晰的知识脉络。什么是滤波器，什么是卷积核，什么是池化，什么是采样，什么是激活函数，什么是分类器，sigmoid是干什么的，全连接是干什么的，怎么有的CNN，什么是前馈网络，什么是反向传递。那些乱七八糟的算子有什么用，SIFT，SVM跟这些东西又是什么关系……等等等等一系列的名称一下子涌过来，搞得我迷迷糊糊。<br>通过不断地学习，不断地温习以往的知识，我开始有了一点点清晰一点的知识脉络。也感谢自己养成了写博客的习惯，今后会慢慢地将自己的理解与认知写下来，理清自己的思路与见解，也供他人参考。如果有读者看到一些错误或者有待商榷的地方，希望您能够不吝指出，与我联系，共同进步。</p><h2 id="从介绍模式识别开始"><a href="#从介绍模式识别开始" class="headerlink" title="从介绍模式识别开始"></a>从介绍模式识别开始</h2><p>刚读研一的时候，张老师让我读《模式识别》（《Pattern Recognition》）这本书。而实际在我真正接触图像识别的工程之前，这本书我仅仅看了第一章，仅仅看了一些概念性的东西，而后面的算法讲解，贝叶斯决策，分类器，支持向量机，多层感知机等等，都因为内容中的公式太多，直接就怕了……感觉这本书会非常的难啃。而后来，在我拜读OpenCV中的关于SVM的算法讲解的时候，有一些地方弄不明白，魏老师让我去看模式识别的分类器这部分，我才茅塞顿开。慢慢也开始进入了良性循环的节奏，看一些公式也不闹心了，也知道一篇论文的重点该看哪里了。非常的nice。</p><p><em>PS：假如我不干编程工作了，大概率可以当个讲师吧！哈哈哈，因为遇到的大部分老师讲一些理论的时候讲的是真的烂啊！！不怪学生们不爱听~自己真正弄明白一些理论之后，真的觉得自己的吹毛求疵，刨根问底都是值得的！研究生阶段的学习，不能是单纯的调用函数接口，还是要深入的了解这个函数。社会的精英阶层，领导阶层什么时候才能真正意识到我们国家的教育问题呢？富人家的孩子暂且可以摆脱经济压力，去国外镀金，花更多的时间投资在个人能力的提升上，但是那些群穷人家的孩子怎么办呢？这大概就是差距慢慢拉大的原因吧~高等教育的改革势在必行，如果能够因材施教，学生找得到自己的兴趣方向，使得学习的驱动力来自于自身，而不是强行往某个领域推。。。我想这样会从上往下传导出一种新的活力吧！估计也不会有这么多人的人生目标是逃离高考大省了吧！</em></p><h3 id="模式识别简介"><a href="#模式识别简介" class="headerlink" title="模式识别简介"></a>模式识别简介</h3><p>传统的模式识别包括且不仅限于一下内容：</p><ul><li>语音识别</li><li>自然语言识别</li><li>字符与文字识别</li><li>图像识别</li><li>动作识别</li></ul><p>而现在比较流行的甚至可以说烂大街的深度学习，也属于模式识别建立分类器的范畴，而这个范畴又包括了</p><ul><li>监督模式识别 (supervised pattern recognition) </li><li>非监督模式识别 (unsupervised pattern recognition)</li></ul><p>而对于监督式模式识别，我们了解的大多数深度学习模型都属于这个范畴。这两种问题的处理方式是有一些区别的。</p><ul><li><strong>对于处理监督模式识别问题的一般步骤是:</strong></li><li>分析问题，分析给定数据哪些因素可以与分类有关。</li><li>原始特征获取。</li><li>特征提取与选择。</li><li>分类器设计，用已知样本进行分类训练。</li><li>分类决策。</li><li><strong>对于处理非监督模式识别问题的一般步骤是：</strong></li><li>分析问题；</li><li>原始特征获取；</li><li>特征提取与选择；</li><li>聚类分析；</li><li>结果解释；<br>对于模式识别中的识别而言，引用维基百科中模式识别的内容来简单解释：<br><code>识别过程与人类的学习过程相似。以光学字符识别之“汉字识别”为例：首先将汉字图像进行处理，抽取主要表达特征并将特征与汉字的代码存在计算机中。就像老师教我们“这个字叫什么、如何写”记在大脑中。这一过程叫做“训练”。识别过程就是将输入的汉字图像经处理后与计算机中的所有字进行比较，找出最相近的字就是识别结果。这一过程叫做“匹配”。</code><br>所以我们大致可以知道模式识别至少包含两个最重要的过程：特征检测与特征匹配（也就是识别）。</li></ul><h2 id="特征检测（特征提取）"><a href="#特征检测（特征提取）" class="headerlink" title="特征检测（特征提取）"></a>特征检测（特征提取）</h2><p>特征检测也是特征提取，它是计算机图像处理整个流水线工作中上游的核心工作了，比如我们拿到一副图片，首先需要进行预处理，这个预处理包括对图形的剪裁，旋转，平移，缩放，二值化等等简单的操作，下一步就是要进行特征检测了，这也是将一个图形从广义图片的范畴调整到数值化，数字化的开端，从这开始我们知道了人们是如何巧妙的将“图片”这种人类感性认知的东西映射到计算机的内存当中的，又是如何让计算机认识它的！</p><p>特征检测可以分为<strong>边缘特征检测</strong>，<strong>角点特征检测</strong>，<strong>斑点特征检测</strong>，<strong>脊检测</strong></p><h3 id="边缘检测-edg-detection"><a href="#边缘检测-edg-detection" class="headerlink" title="边缘检测 [edg detection]"></a>边缘检测 [edg detection]</h3><p>对于边缘检测，如果你上网搜索一下，首先查到的就是各种边缘检测算子，而这些算子无非就是一些$2\ast2$或者$3\ast3$的矩阵罢了。它们又是如何检测图像的边缘的呢？对于一个灰度图像而言，一张图片不过是灰度值从0~255构成的m*n的矩阵罢了。图像矩阵中的每个位置的像素值都是0~255之间的一个数，0就表示没有灰度，就是黑色；255就表示满级的灰度，就是白色。<br>而图片中的边缘是灰度值变化较为明显的地方，这些地方的值与前面的各种边缘滤波器——也就是对应的矩阵做卷积，就会得到高响应，从而判断出哪里是图像的边缘。<br>具体的各类边缘检测算子的区别，我们后续的文章里会继续讨论。但是，到这里，我感觉其实已经可以入门了。实际上检测边缘不是一个简单的问题，如果将边缘认为是一定数量点亮度发生变化的地方，那么边缘检测大体上就是计算这个亮度变化的导数。下图中这个例子，我们的数据是一行不同点亮度的数据。例如，在下面的1维数据中我们可以直观地说在第4与第5个点之间有一个边界：</p><p><img src="/2018/04/25/特征检测技术总结/边缘检测.png" alt="边缘检测"></p><p>除非场景中的物体非常简单并且照明条件得到了很好的控制，否则确定一个用来判断两个相邻点之间有多大的亮度变化才算是有边界的阈值，并不是一件容易的事。实际上，这也是为什么边缘检测不是一个简单问题的原因之一。</p><h4 id="边缘检测的方法"><a href="#边缘检测的方法" class="headerlink" title="边缘检测的方法"></a>边缘检测的方法</h4><p>有许多用于边缘检测的方法，他们大致可分为两类：<strong>基于搜索和基于零交叉</strong>。</p><ol><li>基于搜索的边缘检测方法首先计算边缘强度，通常用一阶导数表示，用计算估计边缘的局部方向，通常采用梯度的方向，并利用此方向找到局部梯度模的最大值。</li><li>基于零交叉的方法找到由图像得到的二阶导数的零交叉点来定位边缘。<br><em>滤波做为边缘检测的预处理通常是必要的，通常采用高斯滤波。</em><br>像我们常见的边缘检测算子包括但不止于：</li></ol><ul><li>Roberts（这是最简单了算子）</li><li>Canny （目前最常用的）</li><li>Sobel</li><li>Isotropic Sobel</li><li>Prewitt</li><li>Laplacian<br>等等一系列算子，都是用来做边缘检测的。<h3 id="角检测（兴趣点检测）-interest-point-detection"><a href="#角检测（兴趣点检测）-interest-point-detection" class="headerlink" title="角检测（兴趣点检测）[interest point detection]"></a>角检测（兴趣点检测）[interest point detection]</h3>与边缘同样重要的一种特征就是角，也是角点，兴趣点；角点的检测经常用于三维建模以及物体识别中。两条边的交点形成一个角（点）。而图像的要点（也称为受关注点）是指图像中具有代表性以及健壮性的点。也就是说，<strong>要点可以是角（点），也可以不是</strong>，例如局部亮点或暗点，线段终点，或者曲线上的曲率最大值点。在实际应用中，很多所谓的（角）点检测算法其实是检测要点，而不仅仅是角（点）。所以，如果我们只想检测角的话，还需要对检测出的要点进一步分析。例如也可以先经过边检测，之后在做一些后处理来检测角。<h4 id="角，兴趣点检测方法"><a href="#角，兴趣点检测方法" class="headerlink" title="角，兴趣点检测方法"></a>角，兴趣点检测方法</h4></li></ul><ol><li>$Moravec$ 角检测算法<br>这是最早使用来做角检测的做法，他首先定义所谓的“角”就是那些自我相似程度低的点。这个算法检查所有图像中的像素，并考虑以该像素为中心点的一片范围，该范围与他周围覆盖最大的另一个范围的相似度做为参考，而相似度通常是将两个范围的对应点计算误差的平方和<code>(SSD: Sum of Squared differences)</code> ，越小代表相似度越高。</li><li>$Harris\,\&amp;\,Stephens/ Plessey / Shi-Tomasi$ 角检测算法<br>$Harris\,\&amp;\,Stephens$改善了$Moravec$的方法，他们直接考虑每个像素沿着特定方向处的像素的SSD，而不是使用与周围像素范围的SSD。详细内容可以查看之前的文章：<br><a href="Harris &amp; Stephens改善了Moravec的方法，他们直接考虑每个像素沿着特定方向处的像素的SSD，而不是使用与周围像素范围的SSD。">Harris Corner Detection</a></li><li>$Förstner$ 角检测<br>在某些情况，会希望更精确地去计算角的位置，为了得到近似值，Förstner 算法可以解出闭集上的角附近范围中的所有切线与最接近这些切线的点，该算法依赖于在一个理想的角附近。<br>这个算法感觉有些复杂目前还没有深入了解…</li><li>多尺度 $Harris$ 算子<br>…这个就看不懂在讲什么了<h3 id="斑点检测"><a href="#斑点检测" class="headerlink" title="斑点检测"></a>斑点检测</h3></li></ol><ul><li>Laplacian of Gaussian (LoG)</li><li>高斯差</li><li>Determinant of Hessian (DoH)</li><li>最大稳定极值区域</li><li>PCBR<h3 id="脊检测"><a href="#脊检测" class="headerlink" title="脊检测"></a>脊检测</h3></li><li>霍夫变换</li><li>广义霍夫变换<h3 id="特征描述"><a href="#特征描述" class="headerlink" title="特征描述"></a>特征描述</h3></li><li>SIFT </li><li>SURF </li><li>GLOH </li><li>HOG</li></ul>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;写在前面&quot;&gt;&lt;a href=&quot;#写在前面&quot; class=&quot;headerlink&quot; title=&quot;写在前面&quot;&gt;&lt;/a&gt;写在前面&lt;/h2&gt;&lt;p&gt;对于模式识别，到了研二终于发自内心的体会到它的应用领域已经广阔到一种不可描述的状态，大到人工智能，数据挖掘，，机器学习，小到
      
    
    </summary>
    
    
      <category term="计算机视觉" scheme="https://stonema.github.io/tags/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/"/>
    
      <category term="图像处理" scheme="https://stonema.github.io/tags/%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86/"/>
    
      <category term="特征" scheme="https://stonema.github.io/tags/%E7%89%B9%E5%BE%81/"/>
    
  </entry>
  
  <entry>
    <title>高频信号与低频信号,图像锐化与模糊</title>
    <link href="https://stonema.github.io/2018/04/24/%E9%AB%98%E9%A2%91%E4%BF%A1%E5%8F%B7%E4%B8%8E%E4%BD%8E%E9%A2%91%E4%BF%A1%E5%8F%B7-%E5%9B%BE%E5%83%8F%E9%94%90%E5%8C%96%E4%B8%8E%E6%A8%A1%E7%B3%8A/"/>
    <id>https://stonema.github.io/2018/04/24/高频信号与低频信号-图像锐化与模糊/</id>
    <published>2018-04-24T05:56:12.000Z</published>
    <updated>2020-01-18T01:45:05.232Z</updated>
    
    <content type="html"><![CDATA[<h2 id="图像频率"><a href="#图像频率" class="headerlink" title="图像频率"></a>图像频率</h2><p>图像处理中经常遇到”处理高频信号”与”处理低频信号”，对于图像而言，频率的高低，就是图像灰度变化的快慢，也就对应了：<strong>高频是噪声和细节，低频是轮廓</strong></p><h3 id="低频"><a href="#低频" class="headerlink" title="低频"></a>低频</h3><p>低频就是颜色缓慢地变化，也就是灰度缓慢地变化，就代表着那是连续渐变的一块区域，这部分就是低频。对于一幅图像来说，除去高频的就是低频了，也就是边缘以外的内容为低频，而边缘的内容就是图像的大部分信息，即图像的大致概貌和轮廓，是图像的近似信息。</p><h3 id="高频"><a href="#高频" class="headerlink" title="高频"></a>高频</h3><p>反过来，高频就是频率变化快。图像中什么时候灰度变化快？就是相邻区域之间灰度相差很大，这就是变化得快的区域。图像中,一个影像与背景的边缘部位，通常会有明显的差别，也就是说变化那条边线那里，灰度变化很快，也即是变化频率高的部位。因此，图像边缘的灰度值变化快，就对应着频率高，即高频显示图像边缘。图像的细节处也是属于灰度值急剧变化的区域，正是因为灰度值的急剧变化，才会出现细节。</p><h3 id="噪点"><a href="#噪点" class="headerlink" title="噪点"></a>噪点</h3><p>另外噪声（即噪点）也是这样，噪点就是与正常的点颜色不一样的区域，也就是说该像素点灰度值有明显差异，也就是灰度值变化过快，所以是高频部分，因此有噪声也属于高频部分。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;图像频率&quot;&gt;&lt;a href=&quot;#图像频率&quot; class=&quot;headerlink&quot; title=&quot;图像频率&quot;&gt;&lt;/a&gt;图像频率&lt;/h2&gt;&lt;p&gt;图像处理中经常遇到”处理高频信号”与”处理低频信号”，对于图像而言，频率的高低，就是图像灰度变化的快慢，也就对应了：&lt;str
      
    
    </summary>
    
      <category term="图像处理" scheme="https://stonema.github.io/categories/%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86/"/>
    
    
      <category term="图像信号" scheme="https://stonema.github.io/tags/%E5%9B%BE%E5%83%8F%E4%BF%A1%E5%8F%B7/"/>
    
      <category term="信号处理" scheme="https://stonema.github.io/tags/%E4%BF%A1%E5%8F%B7%E5%A4%84%E7%90%86/"/>
    
  </entry>
  
</feed>
