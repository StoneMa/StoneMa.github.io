---
title: 从ANN到CNN
date: 2018-05-29 13:09:53
tags: [CNN,卷积神经网络]
categories: [人工智能,机器学习]
mathjax: true
---
**写在前面：** 或许机器学习这部分内容不应该就这么展开，应该循序渐进，待自己有了深层次了解以后，从基本的回归、分类讲起，但是最后还是选择了边学习边总结的形式，至少能详细记录自己曾经踩过的坑，记录自己的学习路线，也算是个好的形式吧！

---
周末跟北京的兄弟们聚了一波，每次见他们的感觉都特别的不一样，每次见完面后都感觉自己受了很大鼓舞，有无限动力。W哥好像一直都是这么的有激情有干劲儿，YL好像一直这么的能钻研从来不觉得累，而且他们的努力程度远在我认识的其他人之上！一起加油~

## **正文：**
## 引言
我相信很多人跟我一样，接触深度学习的最初原因是它很火听起来很厉害，而对于具体是如何实现的，自己根本闹不清……看一些论文、博客的时候都是看到一些类似下图的这样的图片，然后告诉自己：嗯~我大概了解深度学习的概念了。今天我们正儿八经的把它的皮扒开，认真分析它的经脉连通，深入了解什么是神经网络！什么是卷积神经网络，又是如何延伸到深度学习的！
![cnn](./cnn0.png)

这次我们从ANN（人工神经网络）讲解到 CNN（卷积神经网络）带你认识最基本的神经元，然后了解CNN卷积神经网络是如何工作的，然后展开讲它的每一层功能！为了保证我的思路不混乱，保证讲解的路线的正确性，我先以自己踩过的坑为带入点，然后依次深入。
## 1. 从入坑开始 —— CNN
或许这并不是你接触到的深度学习领域，或者是机器学习领域的第一个专业名词，但是搞明白它，足以让我们学习到很多知识以供后续的学习和了解。
CNN（Convolutional Neural Networks）也就是我们常说的卷积神经网络，单单从这个名词来看，这里就有几个概念需要我们来弄明白——什么是**卷积**，什么是**神经网络**。
### 1.1 卷积
最早接触这个词的时候是读大学的时候学习《数字信号处理》这门课程，里面在FFT快速傅里叶变化的时候有讲到卷积运算，$\bigotimes$ 表示卷积运算，那么：
$$
f(x) \bigotimes g(x) = \int_{-\infty}^{+\infty} f(\tau)g(x-\tau)d\tau
$$
离散化的卷积运算：
$$
y(n) = \sum_{i=-\infty}^{+\infty}x(i)h(n-i)=x(n)*h(n)
$$
但是！！这里神经网络中的卷积运算