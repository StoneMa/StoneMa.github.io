---
title: 认识卷积神经网络CNN
date: 2018-06-04 14:53:29
tags: [卷积神经网络,机器学习,感知器]
categories: 神经网络
mathjax: true
---
#卷积神经网络

**卷积神经网络，是一种前馈神经网络，人工神经元可以响应周围单元，可以进行大型图像处理。卷积神经网络包括卷积层和池化层。**

首先来看上一篇文章中的图，这个图就是用来描述CNN
![cnn](./cnn0.png)
## 从入坑开始 —— CNN
或许这并不是你接触到的第一个深度学习领域、或者是机器学习领域的专业名词，但是搞明白它，足以让我们学习到很多知识以供后续的学习和进步。
CNN（Convolutional Neural Networks）也就是我们常说的卷积神经网络，单单从这个名词来看，这里就有几个概念需要我们来弄明白——什么是**卷积**，什么是**神经网络**。

## 卷积
最早接触这个词的时候是读大学的时候学习《数字信号处理》这门课程，里面在FFT快速傅里叶变化的时候有讲到卷积运算，$\bigotimes$ 表示卷积运算，那么：
$$
f(x) \bigotimes g(x) = \int_{-\infty}^{+\infty} f(\tau)g(x-\tau)d\tau\tag{$1$} 
$$
离散化的卷积运算：
$$
y(n) = \sum_{i=-\infty}^{+\infty}x(i)h(n-i)=x(n)*h(n)\tag{$2$} 
$$
但是！！！这里神经网络中的卷积运算，并非傅里叶变换中的卷积运算，这里的卷积运算是以图像和卷积核（也叫滤波器）对应位置相乘再相加得到的结果：如下图所示：
![cnn](./CNN.gif)
图中的黄色区域的标注数字为卷积核，如下所示：
$$
 \left[
 \begin{matrix}
   1 & 0 & 1 \\
   0 & 1 & 0 \\
   1 & 0 & 1
  \end{matrix}
  \right]\tag{$3$} 
$$
我们可以看到，右边得到的结果是左边大矩阵和小矩阵卷积得到的，大矩阵就是我们的原图像，里面的值就是图像像素的值，而小矩阵就是卷积核。两者对应位置相乘然后依次相加，得到新矩阵的一个位置的值，然后向右滑动卷积核（滑动的间隔可调）得到新的位置的值。这就是神经网络中的**卷积**。这里要注意的是，我们从上图中可以看到，卷积核在移动的过程中是一个一个像素滑动的，这个滑动的间隔叫做**步长**（strides），strides的值可以自己设置，表示滑动的间隔的大小。通过这样的操作，我们可以直观的看到，原图像尺寸被卷积操作**缩小**了。这就是卷积操作的作用，可以通过卷积核把一个小区间内的**特征**提取出来，并以数值化的形式表现出来。如果你要深挖为什么要用这样的计算形式来处理卷积核与图形，建议看图像滤波方面的内容。

那么到这里，我们初步具备了学习卷积神经网络的基础知识。Next，我们开始了解卷积神经网络中的各层，以及它们的工作内容。
## 卷积神经网络中的分层
卷积神经网络，是一种前馈神经网络，卷积神经网络包括卷积层和池化层。
## 输入层（Input Layer）
输入层：
该层要做的处理主要是对原始图像数据进行预处理，其中包括：
*	去均值：
把输入数据各个维度都中心化为0，如下图所示，其目的就是把样本的中心拉回到坐标系原点上。
*	归一化：
幅度归一化到同样的范围，如下所示，即减少各维度数据取值范围的差异而带来的干扰，比如，我们有两个维度的特征A和B，A范围是0到10，而B范围是0到10000，如果直接使用这两个特征是有问题的，好的做法就是归一化，即A和B的数据都变为0到1的范围。
*	PCA/白化：
用PCA降维；白化是对数据各个特征轴上的幅度归一化
## 卷积层（Convention Layer）
上面已经介绍了卷积运算的形式，卷积层也是卷积神经网络中最重要的一个层：
卷积在上面，以及之前的文章中我们介绍过它的运算方式，实际卷积的过程或者说卷积运算的过程，就是在提取原矩阵中的特征，（或者理解为对原矩阵做滤波）
## 池化层（Sampling Layer，Pooling Layer）
不知道为什么使用‘池化’这个词，实际这个过程更符合“采样”,我的猜测是“采样”更多的体现的是从已有样本中选择出代表，而池化是使用某些运算后的结果作为代表，并不一定是在原样本中采样。
![pooling](./pooling.gif)
## 全连接（Full-Connection Layer）
## 输出层（Output Layer）

---
有了上面对卷积神经网络的了解，我们要继续了解一下其他内容，下面的前馈网络和BP网络都是对网络中权值更新的算法。
## 前馈神经网络
## BP神经网络
首先不要认为BP网络与卷积网络是并列关系，两者专注的领域不同，BP网络的目的是使用反向传递的思想来更新权值，而卷积网络的目的是降低网络中神经元的连接数量从而减少权值的计算。
### 展开讲反向传递
# 其他网络
# 深度学习
# 参考
[卷积神经网络](./https://www.jianshu.com/p/fe428f0b32c1)